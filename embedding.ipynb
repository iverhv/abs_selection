{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding(2) Feature set\n",
    "former got a lot of cruddle\n",
    "\n",
    "\n",
    "1. load the test set\n",
    "2. load the larger corpus (for embedding training)\n",
    "    - 33k texts\n",
    "    - (Future) : incorporate additional texts to the embedding training\n",
    "3. Hyperparameter tuning (OPTUNA package)\n",
    "    1. Generate the training splits (manual K-foldCV)\n",
    "    2. Pure embedding (global|average|flatten into single neuron)\n",
    "    3. Embedding + ANN\n",
    "    4. Embedding + CNN layer(s)\n",
    "    5. embedding + RNN (very unstable)\n",
    "4. Model evaluation(s)\n",
    "    1. Pure embedding\n",
    "    2. Embedding + shallow CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.5 import and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nktk\n",
    "import nltk\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, f1_score, make_scorer\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# tensorflow/keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding, Flatten, GlobalAveragePooling1D, GlobalMaxPooling1D, Dropout, LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# plotting AUC curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# embedding\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# optuna\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "import optuna.visualization as ov\n",
    "\n",
    "# scikeras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# stats\n",
    "from scipy.stats import sem\n",
    "\n",
    "# saving\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_loss(cv_results):\n",
    "\n",
    "    loss_list = []; val_loss_list = []\n",
    "\n",
    "    for i in cv_results['estimator']:\n",
    "\n",
    "        loss_list.append(i.history_['loss'])\n",
    "        val_loss_list.append(i.history_['val_loss'])\n",
    "\n",
    "    loss_array = np.array(loss_list); val_loss_array = np.array(val_loss_list)\n",
    "    average_loss = loss_array.mean(axis=0); average_val_loss = val_loss_array.mean(axis=0)\n",
    "\n",
    "    plt.plot(average_loss); plt.plot(average_val_loss)\n",
    "    plt.ylim([0.0, 5])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "def text_to_vector(text_list, word2idx, w2v_model):\n",
    "    OOV_token = 'OOV'\n",
    "    \n",
    "    # replace not found tokens with OOV\n",
    "    \n",
    "    new_text = [word if word in word2idx else OOV_token for word in text_list]\n",
    "    \n",
    "    return np.array([w2v_model.wv.key_to_index[word] for word in new_text])\n",
    "\n",
    "def mcc_metric(y_true, y_pred):\n",
    "    predicted = tf.cast(tf.greater(y_pred, 0.5), tf.float32)\n",
    "    true_pos = tf.math.count_nonzero(predicted * y_true)\n",
    "    true_neg = tf.math.count_nonzero((predicted - 1) * (y_true - 1))\n",
    "    false_pos = tf.math.count_nonzero(predicted * (y_true - 1))\n",
    "    false_neg = tf.math.count_nonzero((predicted - 1) * y_true)\n",
    "    x = tf.cast((true_pos + false_pos) * (true_pos + false_neg) \n",
    "      * (true_neg + false_pos) * (true_neg + false_neg), tf.float32)\n",
    "    mcc = tf.cast((true_pos * true_neg) - (false_pos * false_neg), tf.float32) / tf.sqrt(x)\n",
    "\n",
    "    if mcc != np.nan:\n",
    "        return mcc\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def mcc_metric2(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    num = tp * tn - fp * fn\n",
    "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    return num / K.sqrt(den + K.epsilon())\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0.0, 1.5])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "def plot_auc_curve(x_train, x_test, y_train, y_test, model):\n",
    "\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    y_train_pred = model.predict(x_train)\n",
    "\n",
    "    fpr_test, tpr_test, thresholds_keras = roc_curve(y_test, y_test_pred)\n",
    "    fpr_train, tpr_train, thresholds_keras = roc_curve(y_train, y_train_pred)\n",
    "\n",
    "    auc_test = auc(fpr_test, tpr_test)\n",
    "    auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_test, tpr_test, label='train (area = {:.3f})'.format(auc_test))\n",
    "    plt.plot(fpr_train, tpr_train, label='test (area = {:.3f})'.format(auc_train))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    #plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def ann_metrics(model, features, labels):\n",
    "    \n",
    "    y_pred = model.predict(features.astype('float64'), batch_size=1, verbose=0)\n",
    "    #print(y_pred)\n",
    "    \n",
    "    y_pred_bool_manual = []\n",
    "    \n",
    "    for i in y_pred:\n",
    "        if i>0.5:\n",
    "            y_pred_bool_manual.append(1)\n",
    "        else:\n",
    "            y_pred_bool_manual.append(0)\n",
    "    #print(y_pred_bool_manual)\n",
    "    target_names = ['Irrelevant', 'Relevant']\n",
    "    res = classification_report(labels, y_pred_bool_manual, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    print(classification_report(labels, y_pred_bool_manual, target_names=target_names, zero_division=1))\n",
    "    \n",
    "    acc = res['accuracy']\n",
    "    recall = res['Relevant']['recall']\n",
    "    precision = res['Relevant']['precision']\n",
    "    f1 = res['Relevant']['f1-score']\n",
    "    result = [acc, recall, precision, f1]    \n",
    "    \n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def generate_metrics(history, model_emb, X_train, y_train, X_test, y_test):\n",
    "    print('train', model_emb.evaluate(X_train, y_train))\n",
    "    print('train')\n",
    "    _ = ann_metrics(model_emb, X_train, y_train)\n",
    "\n",
    "\n",
    "    print('test', model_emb.evaluate(X_test, y_test))\n",
    "    print('test')\n",
    "    _ = ann_metrics(model_emb, X_test, y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plot_auc_curve(X_train, X_test, y_train, y_test, model_emb)\n",
    "    \n",
    "    #plt.subplot()\n",
    "    #plt.subplot(ax2)\n",
    "    plot_loss(history)\n",
    "    \n",
    "    \n",
    "def scale_mcc(mcc):\n",
    "    return ((mcc-(-1))/(1-(-1)))*(1-0)+0\n",
    "\n",
    "\n",
    "def custom_f1_pos(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def custom_f1_neg(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tn / (tn + fn + K.epsilon())\n",
    "    r = tn / (tn + fp + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 2*((p*r)/(p+r+K.epsilon()))\n",
    "\n",
    "\n",
    "def calculate_f1_score(y, pred, threshold, pos_label):\n",
    "    # if this also wrong, I compute myself\n",
    "    y_pred = pred.copy()\n",
    "\n",
    "    y_pred[y_pred > threshold] = 1\n",
    "    y_pred[y_pred < threshold] = 0\n",
    "\n",
    "    return f1_score(y, y_pred, pos_label=pos_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_json('data/new_test_set_II.json')\n",
    "val_set = pd.read_json('data/validation_set.json')\n",
    "\n",
    "test_set.drop(['DOI'], axis=1, inplace=True)\n",
    "test_set['abstract_tokenized'] = test_set['Abstract'].apply(tokenize)\n",
    "\n",
    "val_set.drop(['doi'], axis=1, inplace=True)\n",
    "val_set['abstract_tokenized'] = val_set['abstract'].apply(tokenize)\n",
    "\n",
    "test_set = test_set.rename(columns={'Abstract': 'abstract', 'Label':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training1 = pd.read_json('data/new_test_set_II.json')\n",
    "training2 = pd.read_json('data/validation_set.json')\n",
    "training1 = training1.rename(columns={'DOI':'doi', 'Abstract': 'abstract', 'Label':'label'})\n",
    "\n",
    "train = pd.concat([training1, training2]).reset_index(drop=True)\n",
    "\n",
    "train['abstract_tokenized'] = train['abstract'].apply(tokenize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate the larger corpus for embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/abstract_df_n42188.json')\n",
    "\n",
    "df = df.dropna()\n",
    "df.drop(['Author', 'Title', 'DOI', 'scp_id'], axis=1, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop_duplicates(subset=['Abstract'], keep='last')\n",
    "\n",
    "df['Abstract_Tokenized'] = df['Abstract'].apply(tokenize)\n",
    "larger_corpus = [tokens for tokens in df['Abstract_Tokenized']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hyperparameter search\n",
    "\n",
    "### 3.0.1 Generate the training splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_fold = []\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    t = train.loc[train_index, :]\n",
    "    v = train.loc[test_index, :]\n",
    "\n",
    "    five_fold.append((t,v))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Pure embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-09-05 14:17:36,063]\u001b[0m A new study created in memory with name: pure_embedding\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-09-05 14:21:11,115]\u001b[0m Trial 0 finished with values: [0.8399999976158142, 0.8968597531318665, 0.8479481177924431, 0.8024441003799438] and parameters: {'vector_size': 97, 'context_window': 7, 'min_count': 4, 'epochs': 7, 'dim': 219, 'padding': 'pre', 'learning_rate': 0.06175283591050675, 'dropout': 0.2641612479032547, 'threshold': 0.39668687769047273}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:26:43,875]\u001b[0m Trial 1 finished with values: [0.8600000023841858, 0.778873085975647, 0.863717519972773, 0.9219106674194336] and parameters: {'vector_size': 85, 'context_window': 5, 'min_count': 6, 'epochs': 13, 'dim': 216, 'padding': 'pre', 'learning_rate': 0.019718734867748347, 'dropout': 0.27571155440689404, 'threshold': 0.6912342726842519}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:32:37,574]\u001b[0m Trial 2 finished with values: [0.5719999969005585, 0.13014911264181137, 0.7986735062108125, 0.95] and parameters: {'vector_size': 63, 'context_window': 8, 'min_count': 4, 'epochs': 13, 'dim': 236, 'padding': 'post', 'learning_rate': 0.0005836112611227828, 'dropout': 0.17993207214547136, 'threshold': 0.7780911538347306}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:35:33,989]\u001b[0m Trial 3 finished with values: [0.8579999923706054, 0.849511444568634, 0.8457422743644354, 0.8593939423561097] and parameters: {'vector_size': 82, 'context_window': 6, 'min_count': 6, 'epochs': 6, 'dim': 230, 'padding': 'pre', 'learning_rate': 0.0010622422619273716, 'dropout': 0.6480035505638378, 'threshold': 0.5559746310629794}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:39:50,175]\u001b[0m Trial 4 finished with values: [0.5119999885559082, 0.9911564588546753, 0.7843624100898563, 0.5008643209934235] and parameters: {'vector_size': 72, 'context_window': 5, 'min_count': 4, 'epochs': 11, 'dim': 247, 'padding': 'post', 'learning_rate': 0.00041035703969044996, 'dropout': 0.6064450125924121, 'threshold': 0.3508595938250224}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:44:49,642]\u001b[0m Trial 5 finished with values: [0.8660000085830688, 0.8425493121147156, 0.8617330191280281, 0.8796324849128723] and parameters: {'vector_size': 76, 'context_window': 8, 'min_count': 4, 'epochs': 10, 'dim': 256, 'padding': 'pre', 'learning_rate': 0.04658612461071634, 'dropout': 0.694357608731937, 'threshold': 0.5894769321008466}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:48:57,529]\u001b[0m Trial 6 finished with values: [0.8439999938011169, 0.927761971950531, 0.8643798655302654, 0.7969242811203003] and parameters: {'vector_size': 57, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 241, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.3035608419348366, 'threshold': 0.36645541231770423}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:54:18,617]\u001b[0m Trial 7 finished with values: [0.7500000119209289, 0.9671421766281127, 0.8594585856666122, 0.6692968010902405] and parameters: {'vector_size': 81, 'context_window': 5, 'min_count': 4, 'epochs': 12, 'dim': 230, 'padding': 'pre', 'learning_rate': 0.0014570581416098636, 'dropout': 0.16786171420739937, 'threshold': 0.30525772491182956}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 14:58:48,007]\u001b[0m Trial 8 finished with values: [0.8099999904632569, 0.9376705646514892, 0.8599913318429762, 0.7400575518608093] and parameters: {'vector_size': 64, 'context_window': 7, 'min_count': 4, 'epochs': 11, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.031077872818086768, 'dropout': 0.5845650814340224, 'threshold': 0.3453641454815213}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:04:34,430]\u001b[0m Trial 9 finished with values: [0.5039999902248382, 0.12167250961065293, 0.6672805124897125, 0.48872082829475405] and parameters: {'vector_size': 63, 'context_window': 9, 'min_count': 6, 'epochs': 12, 'dim': 225, 'padding': 'post', 'learning_rate': 0.00019824106023976634, 'dropout': 0.16522068479311763, 'threshold': 0.6694149509089615}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:08:44,649]\u001b[0m Trial 10 finished with values: [0.8400000095367431, 0.9335889339447021, 0.8724160318053139, 0.779802680015564] and parameters: {'vector_size': 62, 'context_window': 6, 'min_count': 5, 'epochs': 9, 'dim': 213, 'padding': 'pre', 'learning_rate': 0.016348118177174815, 'dropout': 0.2913058946095049, 'threshold': 0.35134792474481147}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:12:58,711]\u001b[0m Trial 11 finished with values: [0.6919999957084656, 0.38476465046405794, 0.8417262259954257, 0.9365079402923584] and parameters: {'vector_size': 95, 'context_window': 9, 'min_count': 5, 'epochs': 7, 'dim': 215, 'padding': 'pre', 'learning_rate': 0.0005337284242922452, 'dropout': 0.5227962972846003, 'threshold': 0.7017988983564876}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:18:33,168]\u001b[0m Trial 12 finished with values: [0.7839999914169311, 0.9663189649581909, 0.8620703359017445, 0.7018375992774963] and parameters: {'vector_size': 83, 'context_window': 8, 'min_count': 5, 'epochs': 10, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.024914324150988945, 'dropout': 0.3266837646724929, 'threshold': 0.23028018057396393}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:25:20,665]\u001b[0m Trial 13 finished with values: [0.5259999930858612, 0.03405895791947842, 0.7552719399378858, 0.6] and parameters: {'vector_size': 63, 'context_window': 9, 'min_count': 6, 'epochs': 13, 'dim': 226, 'padding': 'pre', 'learning_rate': 0.0003618021491890912, 'dropout': 0.2937001266043564, 'threshold': 0.7765409624816468}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:31:12,208]\u001b[0m Trial 14 finished with values: [0.4979999899864197, 0.9962962985038757, 0.6908255576399984, 0.4945025324821472] and parameters: {'vector_size': 78, 'context_window': 5, 'min_count': 6, 'epochs': 12, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.00023620863502499533, 'dropout': 0.1809800340232554, 'threshold': 0.31946928818572035}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:36:45,748]\u001b[0m Trial 15 finished with values: [0.8199999928474426, 0.954217004776001, 0.8692178057876788, 0.7457127809524536] and parameters: {'vector_size': 80, 'context_window': 5, 'min_count': 4, 'epochs': 12, 'dim': 236, 'padding': 'pre', 'learning_rate': 0.013837338558726611, 'dropout': 0.3688788521871006, 'threshold': 0.33112727656309526}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:41:43,479]\u001b[0m Trial 16 finished with values: [0.7300000190734863, 0.9198666930198669, 0.7759616678313013, 0.6681777954101562] and parameters: {'vector_size': 87, 'context_window': 9, 'min_count': 5, 'epochs': 9, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.00017983593649949136, 'dropout': 0.11655133589619304, 'threshold': 0.4863807064527295}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:45:12,290]\u001b[0m Trial 17 finished with values: [0.8460000038146973, 0.9376705646514892, 0.8809418283926235, 0.7873307228088379] and parameters: {'vector_size': 86, 'context_window': 4, 'min_count': 6, 'epochs': 7, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.0038872074456120795, 'dropout': 0.12435046599410203, 'threshold': 0.400628583473042}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:48:28,267]\u001b[0m Trial 18 finished with values: [0.7299999952316284, 0.5318161189556122, 0.782467769671985, 0.8449765801429748] and parameters: {'vector_size': 74, 'context_window': 7, 'min_count': 6, 'epochs': 6, 'dim': 257, 'padding': 'post', 'learning_rate': 0.00033843955070217766, 'dropout': 0.385479352172608, 'threshold': 0.5845344468550986}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:53:44,910]\u001b[0m Trial 19 finished with values: [0.7980000019073487, 0.9497725605964661, 0.8717844127760592, 0.7217223048210144] and parameters: {'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 248, 'padding': 'pre', 'learning_rate': 0.008076709312390297, 'dropout': 0.45592506038880143, 'threshold': 0.3481395299233916}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 15:58:17,462]\u001b[0m Trial 20 finished with values: [0.7419999957084655, 0.9708458781242371, 0.8754519051249317, 0.6603795289993286] and parameters: {'vector_size': 65, 'context_window': 7, 'min_count': 4, 'epochs': 9, 'dim': 250, 'padding': 'pre', 'learning_rate': 0.022362502284241123, 'dropout': 0.6825986278911025, 'threshold': 0.22085158109556471}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:03:15,122]\u001b[0m Trial 21 finished with values: [0.8139999866485595, 0.9347144842147828, 0.8577613424382934, 0.7475289106369019] and parameters: {'vector_size': 56, 'context_window': 6, 'min_count': 6, 'epochs': 12, 'dim': 213, 'padding': 'pre', 'learning_rate': 0.003010549526514929, 'dropout': 0.29111196902654446, 'threshold': 0.38596924952349143}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:06:34,370]\u001b[0m Trial 22 finished with values: [0.8879999876022339, 0.8600700974464417, 0.8637732679837944, 0.9045538067817688] and parameters: {'vector_size': 77, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'post', 'learning_rate': 0.03176099025801702, 'dropout': 0.5136744356192664, 'threshold': 0.5848579651306551}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:10:58,532]\u001b[0m Trial 23 finished with values: [0.7040000081062316, 0.40481550693511964, 0.8625152591393, 0.9632352948188782] and parameters: {'vector_size': 90, 'context_window': 9, 'min_count': 6, 'epochs': 8, 'dim': 210, 'padding': 'pre', 'learning_rate': 0.0012770082360575726, 'dropout': 0.3530509104242916, 'threshold': 0.7677871886007199}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:17:21,910]\u001b[0m Trial 24 finished with values: [0.8680000066757202, 0.9008589267730713, 0.8669480999985391, 0.8398819088935852] and parameters: {'vector_size': 89, 'context_window': 4, 'min_count': 4, 'epochs': 14, 'dim': 216, 'padding': 'post', 'learning_rate': 0.008200999065076656, 'dropout': 0.2368719869678908, 'threshold': 0.49106574275893305}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:21:26,945]\u001b[0m Trial 25 finished with values: [0.5880000054836273, 0.9805648326873779, 0.6890380833184337, 0.5507976710796356] and parameters: {'vector_size': 67, 'context_window': 7, 'min_count': 5, 'epochs': 8, 'dim': 245, 'padding': 'post', 'learning_rate': 0.00011359241216003125, 'dropout': 0.41429685381375114, 'threshold': 0.4328215499764582}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:24:46,458]\u001b[0m Trial 26 finished with values: [0.7679999947547913, 0.5640953838825226, 0.865323468243672, 0.9273573756217957] and parameters: {'vector_size': 58, 'context_window': 9, 'min_count': 5, 'epochs': 6, 'dim': 218, 'padding': 'pre', 'learning_rate': 0.0011708488687078922, 'dropout': 0.4228226569039192, 'threshold': 0.7124538155936133}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:30:58,428]\u001b[0m Trial 27 finished with values: [0.7359999895095826, 0.9425602912902832, 0.8140015974032633, 0.6611780524253845] and parameters: {'vector_size': 67, 'context_window': 5, 'min_count': 6, 'epochs': 14, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.0006740091578774492, 'dropout': 0.6878516139484138, 'threshold': 0.43907704584314067}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:35:29,622]\u001b[0m Trial 28 finished with values: [0.4900000035762787, 1.0, 0.6871299806888858, 0.4900000035762787] and parameters: {'vector_size': 75, 'context_window': 7, 'min_count': 6, 'epochs': 9, 'dim': 216, 'padding': 'pre', 'learning_rate': 0.00014790710080606778, 'dropout': 0.29781604475585965, 'threshold': 0.26515102396423695}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:40:37,469]\u001b[0m Trial 29 finished with values: [0.8239999890327454, 0.954601788520813, 0.8578130042722408, 0.7509061813354492] and parameters: {'vector_size': 59, 'context_window': 9, 'min_count': 4, 'epochs': 10, 'dim': 215, 'padding': 'post', 'learning_rate': 0.05659002800626353, 'dropout': 0.25838989552468994, 'threshold': 0.24084897400697725}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:47:21,471]\u001b[0m Trial 30 finished with values: [0.5100000023841857, 1.0, 0.7747657358879628, 0.499236124753952] and parameters: {'vector_size': 90, 'context_window': 9, 'min_count': 6, 'epochs': 13, 'dim': 252, 'padding': 'post', 'learning_rate': 0.0003213238667748594, 'dropout': 0.43644687607709753, 'threshold': 0.2624435066776917}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:52:52,380]\u001b[0m Trial 31 finished with values: [0.8539999961853028, 0.9262488722801209, 0.8783813255709807, 0.8053905010223389] and parameters: {'vector_size': 86, 'context_window': 5, 'min_count': 6, 'epochs': 12, 'dim': 215, 'padding': 'post', 'learning_rate': 0.0306041922915866, 'dropout': 0.2484606452101512, 'threshold': 0.39456345688144845}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 16:56:51,694]\u001b[0m Trial 32 finished with values: [0.8539999842643737, 0.9300199270248413, 0.8711968673951118, 0.8021466970443726] and parameters: {'vector_size': 84, 'context_window': 6, 'min_count': 5, 'epochs': 8, 'dim': 254, 'padding': 'post', 'learning_rate': 0.01688578979794041, 'dropout': 0.45203443221066797, 'threshold': 0.4262252021135883}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:00:18,585]\u001b[0m Trial 33 finished with values: [0.5759999990463257, 0.9914739251136779, 0.782929794176639, 0.537907725572586] and parameters: {'vector_size': 78, 'context_window': 9, 'min_count': 6, 'epochs': 6, 'dim': 229, 'padding': 'pre', 'learning_rate': 0.0002922461966569062, 'dropout': 0.11725541378697729, 'threshold': 0.3334146210264093}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:06:21,472]\u001b[0m Trial 34 finished with values: [0.7340000033378601, 0.9686305284500122, 0.8349183297166933, 0.6554967164993286] and parameters: {'vector_size': 92, 'context_window': 7, 'min_count': 4, 'epochs': 13, 'dim': 252, 'padding': 'post', 'learning_rate': 0.0005559591875408936, 'dropout': 0.5321768926401884, 'threshold': 0.4106596524908009}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:10:40,248]\u001b[0m Trial 35 finished with values: [0.8659999966621399, 0.8856785535812378, 0.8628115346908984, 0.8500602006912231] and parameters: {'vector_size': 85, 'context_window': 6, 'min_count': 5, 'epochs': 9, 'dim': 216, 'padding': 'pre', 'learning_rate': 0.09466686287162653, 'dropout': 0.38586293901879765, 'threshold': 0.5281757705098151}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:15:54,271]\u001b[0m Trial 36 finished with values: [0.871999990940094, 0.8873043417930603, 0.8691008617070789, 0.8571226596832275] and parameters: {'vector_size': 56, 'context_window': 6, 'min_count': 6, 'epochs': 14, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.48168409474586804}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:20:19,947]\u001b[0m Trial 37 finished with values: [0.8600000023841858, 0.8495787978172302, 0.8603211834088889, 0.8620269536972046] and parameters: {'vector_size': 94, 'context_window': 7, 'min_count': 4, 'epochs': 9, 'dim': 234, 'padding': 'pre', 'learning_rate': 0.03439302487504146, 'dropout': 0.2517356692743894, 'threshold': 0.5950242689250096}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:25:40,834]\u001b[0m Trial 38 finished with values: [0.8559999942779541, 0.938863468170166, 0.8599198123266216, 0.8006796360015869] and parameters: {'vector_size': 70, 'context_window': 9, 'min_count': 4, 'epochs': 11, 'dim': 255, 'padding': 'pre', 'learning_rate': 0.00498923582605686, 'dropout': 0.35378940532177783, 'threshold': 0.424111825580382}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:30:11,019]\u001b[0m Trial 39 finished with values: [0.7899999976158142, 0.9594241738319397, 0.8731924790078107, 0.711774218082428] and parameters: {'vector_size': 62, 'context_window': 7, 'min_count': 4, 'epochs': 9, 'dim': 219, 'padding': 'pre', 'learning_rate': 0.0031277793016711744, 'dropout': 0.292634582089452, 'threshold': 0.30033507326472775}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:35:37,656]\u001b[0m Trial 40 finished with values: [0.5259999930858612, 0.9811035513877868, 0.6853474051594027, 0.5097523629665375] and parameters: {'vector_size': 67, 'context_window': 5, 'min_count': 6, 'epochs': 12, 'dim': 218, 'padding': 'post', 'learning_rate': 0.00010712175129099043, 'dropout': 0.1703654273845282, 'threshold': 0.3622563407591178}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:42:44,945]\u001b[0m Trial 41 finished with values: [0.8519999980926514, 0.9208740353584289, 0.8780130738883724, 0.8065966129302978] and parameters: {'vector_size': 99, 'context_window': 7, 'min_count': 4, 'epochs': 14, 'dim': 222, 'padding': 'pre', 'learning_rate': 0.08333161293122471, 'dropout': 0.5061167431594368, 'threshold': 0.3498747940620328}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:48:07,430]\u001b[0m Trial 42 finished with values: [0.635999983549118, 0.9370123028755188, 0.703451121548659, 0.589437735080719] and parameters: {'vector_size': 82, 'context_window': 9, 'min_count': 6, 'epochs': 10, 'dim': 221, 'padding': 'post', 'learning_rate': 0.0002228597471935027, 'dropout': 0.22351912597167833, 'threshold': 0.4448543035896778}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 17:53:16,169]\u001b[0m Trial 43 finished with values: [0.6299999952316284, 0.9727121591567993, 0.8338656356616593, 0.5766507625579834] and parameters: {'vector_size': 69, 'context_window': 8, 'min_count': 5, 'epochs': 10, 'dim': 239, 'padding': 'pre', 'learning_rate': 0.0004628503286652997, 'dropout': 0.23427504409250227, 'threshold': 0.3667739147683333}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:00:30,468]\u001b[0m Trial 44 finished with values: [0.8420000076293945, 0.9497052073478699, 0.8740889025996864, 0.7745941877365112] and parameters: {'vector_size': 92, 'context_window': 9, 'min_count': 5, 'epochs': 13, 'dim': 216, 'padding': 'post', 'learning_rate': 0.072924851646279, 'dropout': 0.20727923139416127, 'threshold': 0.25950549077026314}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:06:26,061]\u001b[0m Trial 45 finished with values: [0.8519999861717225, 0.9310107827186584, 0.8724532296049323, 0.7995270252227783] and parameters: {'vector_size': 72, 'context_window': 8, 'min_count': 4, 'epochs': 13, 'dim': 247, 'padding': 'pre', 'learning_rate': 0.015249192133183027, 'dropout': 0.3652738620129109, 'threshold': 0.41109764969595985}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:11:11,860]\u001b[0m Trial 46 finished with values: [0.871999990940094, 0.8330928325653076, 0.8699907103049401, 0.9003431916236877] and parameters: {'vector_size': 90, 'context_window': 7, 'min_count': 4, 'epochs': 9, 'dim': 242, 'padding': 'post', 'learning_rate': 0.017366795357882134, 'dropout': 0.1546986556229471, 'threshold': 0.6113280471201261}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:14:22,377]\u001b[0m Trial 47 finished with values: [0.8700000047683716, 0.8711743235588074, 0.8482513711729271, 0.862913191318512] and parameters: {'vector_size': 60, 'context_window': 7, 'min_count': 4, 'epochs': 6, 'dim': 211, 'padding': 'pre', 'learning_rate': 0.06940099325284274, 'dropout': 0.5570597877878822, 'threshold': 0.42363894347549486}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:20:34,542]\u001b[0m Trial 48 finished with values: [0.8660000085830688, 0.8441215038299561, 0.8618830409356726, 0.8775324344635009] and parameters: {'vector_size': 57, 'context_window': 8, 'min_count': 6, 'epochs': 13, 'dim': 251, 'padding': 'pre', 'learning_rate': 0.0027526398996329834, 'dropout': 0.6385385954216792, 'threshold': 0.5613942668681794}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:23:41,476]\u001b[0m Trial 49 finished with values: [0.7860000014305115, 0.6075379729270936, 0.8655177512435055, 0.9294779777526856] and parameters: {'vector_size': 96, 'context_window': 5, 'min_count': 4, 'epochs': 6, 'dim': 241, 'padding': 'post', 'learning_rate': 0.0014567414423655664, 'dropout': 0.5993483227346456, 'threshold': 0.648690599350557}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:29:37,403]\u001b[0m Trial 50 finished with values: [0.7400000095367432, 0.9008960485458374, 0.7787377025329556, 0.6774084329605102] and parameters: {'vector_size': 87, 'context_window': 9, 'min_count': 5, 'epochs': 11, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.00023620863502499533, 'dropout': 0.1809800340232554, 'threshold': 0.4863807064527295}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:34:55,725]\u001b[0m Trial 51 finished with values: [0.728000009059906, 0.9634233474731445, 0.845708756875805, 0.6485182285308838] and parameters: {'vector_size': 67, 'context_window': 4, 'min_count': 6, 'epochs': 12, 'dim': 218, 'padding': 'post', 'learning_rate': 0.0014587405085902398, 'dropout': 0.5806448673875532, 'threshold': 0.3622563407591178}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:39:06,258]\u001b[0m Trial 52 finished with values: [0.8439999938011169, 0.9260661125183105, 0.8559242322932343, 0.78944091796875] and parameters: {'vector_size': 85, 'context_window': 6, 'min_count': 5, 'epochs': 8, 'dim': 254, 'padding': 'post', 'learning_rate': 0.01688578979794041, 'dropout': 0.45203443221066797, 'threshold': 0.4262252021135883}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:44:53,558]\u001b[0m Trial 53 finished with values: [0.8039999961853027, 0.9587439060211181, 0.8623385051420096, 0.72792067527771] and parameters: {'vector_size': 83, 'context_window': 5, 'min_count': 4, 'epochs': 12, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.024914324150988945, 'dropout': 0.3266837646724929, 'threshold': 0.23028018057396393}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:48:12,451]\u001b[0m Trial 54 finished with values: [0.7140000104904175, 0.975290322303772, 0.8705531942314609, 0.6350682258605957] and parameters: {'vector_size': 65, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 250, 'padding': 'pre', 'learning_rate': 0.022362502284241123, 'dropout': 0.6825986278911025, 'threshold': 0.22085158109556471}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:54:32,420]\u001b[0m Trial 55 finished with values: [0.5900000095367431, 0.9804150462150574, 0.8162869128247128, 0.5448971927165985] and parameters: {'vector_size': 75, 'context_window': 7, 'min_count': 5, 'epochs': 13, 'dim': 216, 'padding': 'pre', 'learning_rate': 0.0006022949168835941, 'dropout': 0.29781604475585965, 'threshold': 0.25950549077026314}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 18:59:24,455]\u001b[0m Trial 56 finished with values: [0.6519999980926514, 0.9807929754257202, 0.8510237255369999, 0.5860239505767822] and parameters: {'vector_size': 81, 'context_window': 5, 'min_count': 4, 'epochs': 10, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.0014570581416098636, 'dropout': 0.3266837646724929, 'threshold': 0.23028018057396393}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:05:10,604]\u001b[0m Trial 57 finished with values: [0.7639999985694885, 0.9450546264648437, 0.8046749913386542, 0.6925646066665649] and parameters: {'vector_size': 67, 'context_window': 5, 'min_count': 6, 'epochs': 14, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.0006740091578774492, 'dropout': 0.6878516139484138, 'threshold': 0.49106574275893305}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:09:59,273]\u001b[0m Trial 58 finished with values: [0.5519999921321869, 0.9825850367546082, 0.692868948155214, 0.5220559954643249] and parameters: {'vector_size': 63, 'context_window': 9, 'min_count': 5, 'epochs': 10, 'dim': 257, 'padding': 'pre', 'learning_rate': 0.0002228597471935027, 'dropout': 0.22351912597167833, 'threshold': 0.3334146210264093}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:15:28,967]\u001b[0m Trial 59 finished with values: [0.5559999883174896, 0.9886456370353699, 0.7039066976549304, 0.5266562283039093] and parameters: {'vector_size': 69, 'context_window': 8, 'min_count': 6, 'epochs': 12, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.00023620863502499533, 'dropout': 0.1809800340232554, 'threshold': 0.3667739147683333}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:20:18,592]\u001b[0m Trial 60 finished with values: [0.877999997138977, 0.9008589267730713, 0.880663200614846, 0.8570821404457092] and parameters: {'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 248, 'padding': 'pre', 'learning_rate': 0.008076709312390297, 'dropout': 0.45592506038880143, 'threshold': 0.5188836233727432}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:25:41,202]\u001b[0m Trial 61 finished with values: [0.7340000033378601, 0.4676465272903442, 0.8712232779273394, 0.9577777743339538] and parameters: {'vector_size': 90, 'context_window': 9, 'min_count': 6, 'epochs': 11, 'dim': 249, 'padding': 'pre', 'learning_rate': 0.0012770082360575726, 'dropout': 0.3530509104242916, 'threshold': 0.7677871886007199}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:29:52,338]\u001b[0m Trial 62 finished with values: [0.8860000014305115, 0.8685741782188415, 0.8685768883215692, 0.8966945052146912] and parameters: {'vector_size': 57, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 248, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.3035608419348366, 'threshold': 0.598413172203673}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:35:03,813]\u001b[0m Trial 63 finished with values: [0.8379999995231628, 0.9387356519699097, 0.8847707965556909, 0.7752236485481262] and parameters: {'vector_size': 59, 'context_window': 9, 'min_count': 4, 'epochs': 10, 'dim': 215, 'padding': 'post', 'learning_rate': 0.003010549526514929, 'dropout': 0.29111196902654446, 'threshold': 0.38596924952349143}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:40:47,113]\u001b[0m Trial 64 finished with values: [0.8279999852180481, 0.9275091052055359, 0.8731005053230346, 0.768350076675415] and parameters: {'vector_size': 83, 'context_window': 8, 'min_count': 4, 'epochs': 11, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.031077872818086768, 'dropout': 0.3266837646724929, 'threshold': 0.3453641454815213}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:46:43,193]\u001b[0m Trial 65 finished with values: [0.7480000138282776, 0.9641860842704773, 0.8377041203349043, 0.6685541868209839] and parameters: {'vector_size': 92, 'context_window': 7, 'min_count': 4, 'epochs': 12, 'dim': 213, 'padding': 'post', 'learning_rate': 0.0005559591875408936, 'dropout': 0.29111196902654446, 'threshold': 0.4106596524908009}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:53:22,486]\u001b[0m Trial 66 finished with values: [0.7100000143051147, 0.9715866208076477, 0.86319445549652, 0.6321707606315613] and parameters: {'vector_size': 83, 'context_window': 6, 'min_count': 5, 'epochs': 14, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.23028018057396393}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 19:56:30,521]\u001b[0m Trial 67 finished with values: [0.8639999985694885, 0.809978699684143, 0.8618271996305081, 0.9048617839813232] and parameters: {'vector_size': 60, 'context_window': 7, 'min_count': 4, 'epochs': 6, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.03176099025801702, 'dropout': 0.5570597877878822, 'threshold': 0.5848579651306551}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:01:20,792]\u001b[0m Trial 68 finished with values: [0.527999997138977, 0.9914739251136779, 0.7803841794569066, 0.508681857585907] and parameters: {'vector_size': 58, 'context_window': 4, 'min_count': 4, 'epochs': 11, 'dim': 247, 'padding': 'post', 'learning_rate': 0.00041035703969044996, 'dropout': 0.2758567336390119, 'threshold': 0.3508595938250224}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:07:06,880]\u001b[0m Trial 69 finished with values: [0.850000011920929, 0.9292118430137635, 0.8657301728598986, 0.7965188384056091] and parameters: {'vector_size': 99, 'context_window': 7, 'min_count': 4, 'epochs': 11, 'dim': 222, 'padding': 'pre', 'learning_rate': 0.08333161293122471, 'dropout': 0.28363322974347577, 'threshold': 0.424111825580382}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:12:30,577]\u001b[0m Trial 70 finished with values: [0.771999990940094, 0.9715866208076477, 0.8731890758127022, 0.6889812469482421] and parameters: {'vector_size': 65, 'context_window': 7, 'min_count': 4, 'epochs': 11, 'dim': 213, 'padding': 'pre', 'learning_rate': 0.00498923582605686, 'dropout': 0.35378940532177783, 'threshold': 0.22085158109556471}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:16:28,856]\u001b[0m Trial 71 finished with values: [0.8660000085830688, 0.920496118068695, 0.855985334105816, 0.8254461526870728] and parameters: {'vector_size': 97, 'context_window': 7, 'min_count': 4, 'epochs': 7, 'dim': 241, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.2641612479032547, 'threshold': 0.39668687769047273}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:22:37,223]\u001b[0m Trial 72 finished with values: [0.8340000152587891, 0.7234590888023377, 0.8666594433225828, 0.9162202119827271] and parameters: {'vector_size': 85, 'context_window': 5, 'min_count': 4, 'epochs': 13, 'dim': 230, 'padding': 'pre', 'learning_rate': 0.013837338558726611, 'dropout': 0.3688788521871006, 'threshold': 0.6912342726842519}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:29:15,726]\u001b[0m Trial 73 finished with values: [0.8180000066757203, 0.9462035298347473, 0.8647995670478276, 0.7485522150993347] and parameters: {'vector_size': 99, 'context_window': 9, 'min_count': 4, 'epochs': 13, 'dim': 216, 'padding': 'post', 'learning_rate': 0.04674847682415191, 'dropout': 0.20727923139416127, 'threshold': 0.25950549077026314}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:34:43,646]\u001b[0m Trial 74 finished with values: [0.8460000038146973, 0.9421823620796204, 0.8653977975588024, 0.7838133573532104] and parameters: {'vector_size': 58, 'context_window': 9, 'min_count': 4, 'epochs': 12, 'dim': 236, 'padding': 'pre', 'learning_rate': 0.013837338558726611, 'dropout': 0.3688788521871006, 'threshold': 0.33112727656309526}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:40:43,065]\u001b[0m Trial 75 finished with values: [0.8600000023841858, 0.8128660798072815, 0.8793577735989906, 0.8956371426582337] and parameters: {'vector_size': 63, 'context_window': 9, 'min_count': 4, 'epochs': 13, 'dim': 220, 'padding': 'post', 'learning_rate': 0.06940099325284274, 'dropout': 0.2937001266043564, 'threshold': 0.626312425986365}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:47:05,732]\u001b[0m Trial 76 finished with values: [0.8679999947547913, 0.803175973892212, 0.8726098754735286, 0.9154129147529602] and parameters: {'vector_size': 69, 'context_window': 6, 'min_count': 6, 'epochs': 14, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.6127060603215981}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:50:36,573]\u001b[0m Trial 77 finished with values: [0.8639999985694885, 0.9181007266044616, 0.8743806385281635, 0.8255503177642822] and parameters: {'vector_size': 60, 'context_window': 7, 'min_count': 4, 'epochs': 7, 'dim': 219, 'padding': 'pre', 'learning_rate': 0.06940099325284274, 'dropout': 0.2641612479032547, 'threshold': 0.39668687769047273}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 20:56:34,099]\u001b[0m Trial 78 finished with values: [0.8220000028610229, 0.9541496515274048, 0.8640757698742144, 0.748492443561554] and parameters: {'vector_size': 85, 'context_window': 5, 'min_count': 6, 'epochs': 13, 'dim': 216, 'padding': 'post', 'learning_rate': 0.072924851646279, 'dropout': 0.20727923139416127, 'threshold': 0.25950549077026314}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:01:20,591]\u001b[0m Trial 79 finished with values: [0.722000002861023, 0.9840514063835144, 0.8601334346430365, 0.6401177287101746] and parameters: {'vector_size': 72, 'context_window': 5, 'min_count': 4, 'epochs': 11, 'dim': 247, 'padding': 'post', 'learning_rate': 0.0047066467461851485, 'dropout': 0.6064450125924121, 'threshold': 0.22824384026433708}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:06:31,272]\u001b[0m Trial 80 finished with values: [0.8560000061988831, 0.9143970251083374, 0.8585035741641315, 0.8173197507858276] and parameters: {'vector_size': 83, 'context_window': 8, 'min_count': 5, 'epochs': 10, 'dim': 255, 'padding': 'pre', 'learning_rate': 0.024914324150988945, 'dropout': 0.3266837646724929, 'threshold': 0.424111825580382}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:12:05,989]\u001b[0m Trial 81 finished with values: [0.8420000076293945, 0.7439950585365296, 0.8737075185365084, 0.9190223217010498] and parameters: {'vector_size': 78, 'context_window': 5, 'min_count': 4, 'epochs': 12, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.01033647175166428, 'dropout': 0.5993483227346456, 'threshold': 0.648690599350557}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:18:06,083]\u001b[0m Trial 82 finished with values: [0.8220000028610229, 0.7629231095314026, 0.825993076263645, 0.8591470718383789] and parameters: {'vector_size': 61, 'context_window': 7, 'min_count': 6, 'epochs': 13, 'dim': 229, 'padding': 'post', 'learning_rate': 0.0005836112611227828, 'dropout': 0.10333068308776, 'threshold': 0.5848579651306551}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:21:54,448]\u001b[0m Trial 83 finished with values: [0.8419999957084656, 0.9236707210540771, 0.8593017886356853, 0.7897034287452698] and parameters: {'vector_size': 97, 'context_window': 7, 'min_count': 4, 'epochs': 7, 'dim': 219, 'padding': 'pre', 'learning_rate': 0.0914677487603344, 'dropout': 0.2641612479032547, 'threshold': 0.39668687769047273}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:27:25,750]\u001b[0m Trial 84 finished with values: [0.8419999957084656, 0.7382903814315795, 0.855104913352968, 0.9221868753433228] and parameters: {'vector_size': 85, 'context_window': 5, 'min_count': 6, 'epochs': 13, 'dim': 232, 'padding': 'pre', 'learning_rate': 0.019718734867748347, 'dropout': 0.27571155440689404, 'threshold': 0.722286519136603}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:31:32,997]\u001b[0m Trial 85 finished with values: [0.6019999980926514, 0.6596083343029022, 0.6748888301320358, 0.5821030557155609] and parameters: {'vector_size': 85, 'context_window': 5, 'min_count': 5, 'epochs': 9, 'dim': 216, 'padding': 'post', 'learning_rate': 0.00010712175129099043, 'dropout': 0.38586293901879765, 'threshold': 0.5281757705098151}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:35:26,528]\u001b[0m Trial 86 finished with values: [0.8559999942779541, 0.8251508355140686, 0.8627825920849176, 0.8725774884223938] and parameters: {'vector_size': 57, 'context_window': 5, 'min_count': 4, 'epochs': 9, 'dim': 234, 'padding': 'pre', 'learning_rate': 0.03439302487504146, 'dropout': 0.2517356692743894, 'threshold': 0.5950242689250096}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:40:34,858]\u001b[0m Trial 87 finished with values: [0.8480000138282776, 0.735411274433136, 0.8730671201216831, 0.937587833404541] and parameters: {'vector_size': 80, 'context_window': 9, 'min_count': 4, 'epochs': 12, 'dim': 218, 'padding': 'pre', 'learning_rate': 0.013837338558726611, 'dropout': 0.3688788521871006, 'threshold': 0.7124538155936133}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:45:52,212]\u001b[0m Trial 88 finished with values: [0.8419999957084656, 0.9364845752716064, 0.8543154022334422, 0.781655752658844] and parameters: {'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 234, 'padding': 'post', 'learning_rate': 0.03439302487504146, 'dropout': 0.2517356692743894, 'threshold': 0.3481395299233916}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:52:15,544]\u001b[0m Trial 89 finished with values: [0.7799999952316284, 0.6703868746757508, 0.8323084844382354, 0.8481613993644714] and parameters: {'vector_size': 92, 'context_window': 7, 'min_count': 4, 'epochs': 13, 'dim': 252, 'padding': 'pre', 'learning_rate': 0.0005559591875408936, 'dropout': 0.5321768926401884, 'threshold': 0.5950242689250096}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 21:55:35,285]\u001b[0m Trial 90 finished with values: [0.7399999976158143, 0.6210760772228241, 0.783807259208779, 0.8216241478919983] and parameters: {'vector_size': 90, 'context_window': 7, 'min_count': 6, 'epochs': 6, 'dim': 257, 'padding': 'post', 'learning_rate': 0.0003213238667748594, 'dropout': 0.43644687607709753, 'threshold': 0.5845344468550986}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:00:12,862]\u001b[0m Trial 91 finished with values: [0.7940000057220459, 0.9553425312042236, 0.8599594086582607, 0.7170192718505859] and parameters: {'vector_size': 56, 'context_window': 6, 'min_count': 6, 'epochs': 11, 'dim': 212, 'padding': 'post', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.3508595938250224}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:05:04,249]\u001b[0m Trial 92 finished with values: [0.8360000014305115, 0.9469442725181579, 0.8682028943025323, 0.7696730852127075] and parameters: {'vector_size': 81, 'context_window': 5, 'min_count': 4, 'epochs': 10, 'dim': 239, 'padding': 'pre', 'learning_rate': 0.005730007527214668, 'dropout': 0.23427504409250227, 'threshold': 0.3667739147683333}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:08:35,053]\u001b[0m Trial 93 finished with values: [0.5159999907016755, 1.0, 0.7131789275462885, 0.5035043895244599] and parameters: {'vector_size': 72, 'context_window': 4, 'min_count': 6, 'epochs': 8, 'dim': 247, 'padding': 'pre', 'learning_rate': 0.00041035703969044996, 'dropout': 0.6064450125924121, 'threshold': 0.3508595938250224}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:11:57,545]\u001b[0m Trial 94 finished with values: [0.8699999928474427, 0.876359510421753, 0.8664884199709821, 0.8601428270339966] and parameters: {'vector_size': 89, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.008200999065076656, 'dropout': 0.2368719869678908, 'threshold': 0.49106574275893305}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:16:26,863]\u001b[0m Trial 95 finished with values: [0.8459999918937683, 0.9553425312042236, 0.8613765492554084, 0.782619035243988] and parameters: {'vector_size': 88, 'context_window': 9, 'min_count': 6, 'epochs': 9, 'dim': 245, 'padding': 'post', 'learning_rate': 0.05659002800626353, 'dropout': 0.29781604475585965, 'threshold': 0.3349786355102691}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:20:22,000]\u001b[0m Trial 96 finished with values: [0.8159999847412109, 0.9413742780685425, 0.8459047325248974, 0.7480244994163513] and parameters: {'vector_size': 77, 'context_window': 9, 'min_count': 5, 'epochs': 7, 'dim': 219, 'padding': 'post', 'learning_rate': 0.072924851646279, 'dropout': 0.20727923139416127, 'threshold': 0.25950549077026314}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:23:48,666]\u001b[0m Trial 97 finished with values: [0.865999984741211, 0.8981680750846863, 0.8679446987829079, 0.8405611634254455] and parameters: {'vector_size': 92, 'context_window': 9, 'min_count': 5, 'epochs': 6, 'dim': 211, 'padding': 'pre', 'learning_rate': 0.072924851646279, 'dropout': 0.5570597877878822, 'threshold': 0.42363894347549486}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:27:33,842]\u001b[0m Trial 98 finished with values: [0.7899999976158142, 0.7506314754486084, 0.8049045691150954, 0.8094061255455017] and parameters: {'vector_size': 63, 'context_window': 8, 'min_count': 4, 'epochs': 7, 'dim': 236, 'padding': 'pre', 'learning_rate': 0.0005836112611227828, 'dropout': 0.6385385954216792, 'threshold': 0.5613942668681794}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-05 22:32:25,752]\u001b[0m Trial 99 finished with values: [0.8419999957084656, 0.7672397494316101, 0.859741935483871, 0.8951149463653565] and parameters: {'vector_size': 57, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.0018472280899948757, 'dropout': 0.694357608731937, 'threshold': 0.5894769321008466}. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def initiate_embedding(vector_size, window, min_count, epochs, larger_corpus=larger_corpus):\n",
    "    # Train a Word2Vec model on the larger corpus\n",
    "    w2v_model = Word2Vec(larger_corpus, vector_size=vector_size,\n",
    "                                        window=window, \n",
    "                                        min_count=min_count, \n",
    "                                        workers=4, \n",
    "                                        epochs=epochs)\n",
    "    \n",
    "    # out of vocabulary token\n",
    "    OOV_token = 'OOV'\n",
    "\n",
    "    zero_vector = np.zeros(vector_size)\n",
    "    index = len(w2v_model.wv.key_to_index)\n",
    "    w2v_model.wv.key_to_index[OOV_token] = index\n",
    "    index_to_key = list(w2v_model.wv.index_to_key) + [OOV_token]\n",
    "    w2v_model.wv.index_to_key = index_to_key\n",
    "    w2v_model.wv.vectors = np.concatenate((w2v_model.wv.vectors, [zero_vector]), axis=0)\n",
    "\n",
    "    # Extract the embedding weights from the trained model\n",
    "    embedding_weights = w2v_model.wv.vectors\n",
    "    \n",
    "    return w2v_model, embedding_weights\n",
    "\n",
    "def features(training_data, model, dim, padding):\n",
    "    # Step 1: Create a mapping between words in the test set and the corresponding word embeddings\n",
    "    word2idx = {word: i for i, word in enumerate(model.wv.index_to_key)}\n",
    "\n",
    "    training_data['keys'] = training_data['abstract_tokenized'].apply(text_to_vector, word2idx=word2idx, w2v_model=model)\n",
    "    padded = pad_sequences(training_data['keys'], dim, padding=padding, truncating=padding)\n",
    "    \n",
    "    X = padded\n",
    "    y = training_data['label'].values\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "def create_embedding_model(trial, dim, embedding_weights):\n",
    "\n",
    "    # model parameters\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.7)\n",
    "    threshold = trial.suggest_float('threshold', 0.2, 0.8)\n",
    "    #k_reg = trial.suggest_float('regularizers', 1e-4, 1e-0, log=True)\n",
    "    \n",
    "    model_emb = keras.Sequential([keras.layers.Embedding(input_dim=embedding_weights.shape[0],\n",
    "                                                     output_dim=embedding_weights.shape[1],\n",
    "                                                     input_length = dim,\n",
    "                                                     weights=[embedding_weights], trainable=False),\n",
    "                                \n",
    "\n",
    "                                  keras.layers.GlobalAveragePooling1D(),\n",
    "                                  keras.layers.Dropout(dropout),\n",
    "\n",
    "                                  \n",
    "                                  #keras.layers.Dense(10, activation='relu', kernel_regularizer=regularizers.L1(k_reg)),\n",
    "\n",
    "                                  keras.layers.Dense(1, activation='sigmoid')\n",
    "                                ])\n",
    "        \n",
    "    \n",
    "    model_emb.compile(optimizer = keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['AUC', keras.metrics.BinaryAccuracy(threshold=threshold),\n",
    "                                      keras.metrics.Recall(thresholds=threshold),\n",
    "                                      keras.metrics.Precision(thresholds=threshold),])\n",
    "    return model_emb\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # embedding model\n",
    "    vector_size = trial.suggest_int('vector_size', 55, 100)\n",
    "    window = trial.suggest_int('context_window', 4, 9)\n",
    "    min_count = trial.suggest_int('min_count', 4, 6)\n",
    "    epochs = trial.suggest_int('epochs', 6, 14)\n",
    "    \n",
    "    sample_dim = trial.suggest_int('dim', 210, 260)\n",
    "    padding = trial.suggest_categorical('padding', ['pre', 'post'])\n",
    "    \n",
    "    #batch_size = trial.suggest_int('batch_size', 1, 200)\n",
    "    loss_list = []; auc_list = []; acc_list = []; rec_list = []; prec_list = []; f1_list = []\n",
    "    \n",
    "    for train, val in five_fold:\n",
    "        #print(train, val)\n",
    "\n",
    "        model, embedding_weights = initiate_embedding(vector_size, window, min_count, epochs)\n",
    "        \n",
    "        \n",
    "        #X_train, y_train, X_test, y_test = features(train, model, sample_dim, padding)\n",
    "        X_train, y_train = features(train, model, sample_dim, padding)\n",
    "        X_test, y_test = features(val, model, sample_dim, padding)\n",
    "\n",
    "        emb_model = create_embedding_model(trial, sample_dim, embedding_weights)\n",
    "\n",
    "        emb_model.fit(X_train, y_train, verbose=0, validation_split=0.25, epochs=100, batch_size=100)\n",
    "    \n",
    "        score = emb_model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        loss_list.append(score[0])\n",
    "        auc_list.append(score[1])\n",
    "        acc_list.append(score[2])\n",
    "        rec_list.append(score[3])\n",
    "        prec_list.append(score[4])\n",
    "\n",
    "        y_pred = emb_model.predict(X_test, verbose=0)\n",
    "        f1_list.append(calculate_f1_score(y_test, y_pred, threshold=.5, pos_label=1))\n",
    "\n",
    "    return  np.array(acc_list).mean(), np.array(rec_list).mean(), np.array(f1_list).mean(), np.array(prec_list).mean()\n",
    "\n",
    "\n",
    "study_pure = optuna.create_study(study_name='pure_embedding',\n",
    "                                 directions=['maximize', 'maximize', 'maximize', 'maximize'],  \n",
    "                                 sampler=optuna.samplers.NSGAIISampler())\n",
    "\n",
    "study_pure.optimize(objective, n_trials=100, n_jobs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model#:  1\n",
      "performance:  [0.8600000023841858, 0.778873085975647, 0.863717519972773, 0.9219106674194336]\n",
      "parameter_set:  {'vector_size': 85, 'context_window': 5, 'min_count': 6, 'epochs': 13, 'dim': 216, 'padding': 'pre', 'learning_rate': 0.019718734867748347, 'dropout': 0.27571155440689404, 'threshold': 0.6912342726842519}\n",
      "model#:  4\n",
      "performance:  [0.5119999885559082, 0.9911564588546753, 0.7843624100898563, 0.5008643209934235]\n",
      "parameter_set:  {'vector_size': 72, 'context_window': 5, 'min_count': 4, 'epochs': 11, 'dim': 247, 'padding': 'post', 'learning_rate': 0.00041035703969044996, 'dropout': 0.6064450125924121, 'threshold': 0.3508595938250224}\n",
      "model#:  12\n",
      "performance:  [0.7839999914169311, 0.9663189649581909, 0.8620703359017445, 0.7018375992774963]\n",
      "parameter_set:  {'vector_size': 83, 'context_window': 8, 'min_count': 5, 'epochs': 10, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.024914324150988945, 'dropout': 0.3266837646724929, 'threshold': 0.23028018057396393}\n",
      "model#:  15\n",
      "performance:  [0.8199999928474426, 0.954217004776001, 0.8692178057876788, 0.7457127809524536]\n",
      "parameter_set:  {'vector_size': 80, 'context_window': 5, 'min_count': 4, 'epochs': 12, 'dim': 236, 'padding': 'pre', 'learning_rate': 0.013837338558726611, 'dropout': 0.3688788521871006, 'threshold': 0.33112727656309526}\n",
      "model#:  17\n",
      "performance:  [0.8460000038146973, 0.9376705646514892, 0.8809418283926235, 0.7873307228088379]\n",
      "parameter_set:  {'vector_size': 86, 'context_window': 4, 'min_count': 6, 'epochs': 7, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.0038872074456120795, 'dropout': 0.12435046599410203, 'threshold': 0.400628583473042}\n",
      "model#:  19\n",
      "performance:  [0.7980000019073487, 0.9497725605964661, 0.8717844127760592, 0.7217223048210144]\n",
      "parameter_set:  {'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 248, 'padding': 'pre', 'learning_rate': 0.008076709312390297, 'dropout': 0.45592506038880143, 'threshold': 0.3481395299233916}\n",
      "model#:  20\n",
      "performance:  [0.7419999957084655, 0.9708458781242371, 0.8754519051249317, 0.6603795289993286]\n",
      "parameter_set:  {'vector_size': 65, 'context_window': 7, 'min_count': 4, 'epochs': 9, 'dim': 250, 'padding': 'pre', 'learning_rate': 0.022362502284241123, 'dropout': 0.6825986278911025, 'threshold': 0.22085158109556471}\n",
      "model#:  22\n",
      "performance:  [0.8879999876022339, 0.8600700974464417, 0.8637732679837944, 0.9045538067817688]\n",
      "parameter_set:  {'vector_size': 77, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'post', 'learning_rate': 0.03176099025801702, 'dropout': 0.5136744356192664, 'threshold': 0.5848579651306551}\n",
      "model#:  23\n",
      "performance:  [0.7040000081062316, 0.40481550693511964, 0.8625152591393, 0.9632352948188782]\n",
      "parameter_set:  {'vector_size': 90, 'context_window': 9, 'min_count': 6, 'epochs': 8, 'dim': 210, 'padding': 'pre', 'learning_rate': 0.0012770082360575726, 'dropout': 0.3530509104242916, 'threshold': 0.7677871886007199}\n",
      "model#:  30\n",
      "performance:  [0.5100000023841857, 1.0, 0.7747657358879628, 0.499236124753952]\n",
      "parameter_set:  {'vector_size': 90, 'context_window': 9, 'min_count': 6, 'epochs': 13, 'dim': 252, 'padding': 'post', 'learning_rate': 0.0003213238667748594, 'dropout': 0.43644687607709753, 'threshold': 0.2624435066776917}\n",
      "model#:  31\n",
      "performance:  [0.8539999961853028, 0.9262488722801209, 0.8783813255709807, 0.8053905010223389]\n",
      "parameter_set:  {'vector_size': 86, 'context_window': 5, 'min_count': 6, 'epochs': 12, 'dim': 215, 'padding': 'post', 'learning_rate': 0.0306041922915866, 'dropout': 0.2484606452101512, 'threshold': 0.39456345688144845}\n",
      "model#:  32\n",
      "performance:  [0.8539999842643737, 0.9300199270248413, 0.8711968673951118, 0.8021466970443726]\n",
      "parameter_set:  {'vector_size': 84, 'context_window': 6, 'min_count': 5, 'epochs': 8, 'dim': 254, 'padding': 'post', 'learning_rate': 0.01688578979794041, 'dropout': 0.45203443221066797, 'threshold': 0.4262252021135883}\n",
      "model#:  33\n",
      "performance:  [0.5759999990463257, 0.9914739251136779, 0.782929794176639, 0.537907725572586]\n",
      "parameter_set:  {'vector_size': 78, 'context_window': 9, 'min_count': 6, 'epochs': 6, 'dim': 229, 'padding': 'pre', 'learning_rate': 0.0002922461966569062, 'dropout': 0.11725541378697729, 'threshold': 0.3334146210264093}\n",
      "model#:  36\n",
      "performance:  [0.871999990940094, 0.8873043417930603, 0.8691008617070789, 0.8571226596832275]\n",
      "parameter_set:  {'vector_size': 56, 'context_window': 6, 'min_count': 6, 'epochs': 14, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.48168409474586804}\n",
      "model#:  38\n",
      "performance:  [0.8559999942779541, 0.938863468170166, 0.8599198123266216, 0.8006796360015869]\n",
      "parameter_set:  {'vector_size': 70, 'context_window': 9, 'min_count': 4, 'epochs': 11, 'dim': 255, 'padding': 'pre', 'learning_rate': 0.00498923582605686, 'dropout': 0.35378940532177783, 'threshold': 0.424111825580382}\n",
      "model#:  39\n",
      "performance:  [0.7899999976158142, 0.9594241738319397, 0.8731924790078107, 0.711774218082428]\n",
      "parameter_set:  {'vector_size': 62, 'context_window': 7, 'min_count': 4, 'epochs': 9, 'dim': 219, 'padding': 'pre', 'learning_rate': 0.0031277793016711744, 'dropout': 0.292634582089452, 'threshold': 0.30033507326472775}\n",
      "model#:  41\n",
      "performance:  [0.8519999980926514, 0.9208740353584289, 0.8780130738883724, 0.8065966129302978]\n",
      "parameter_set:  {'vector_size': 99, 'context_window': 7, 'min_count': 4, 'epochs': 14, 'dim': 222, 'padding': 'pre', 'learning_rate': 0.08333161293122471, 'dropout': 0.5061167431594368, 'threshold': 0.3498747940620328}\n",
      "model#:  44\n",
      "performance:  [0.8420000076293945, 0.9497052073478699, 0.8740889025996864, 0.7745941877365112]\n",
      "parameter_set:  {'vector_size': 92, 'context_window': 9, 'min_count': 5, 'epochs': 13, 'dim': 216, 'padding': 'post', 'learning_rate': 0.072924851646279, 'dropout': 0.20727923139416127, 'threshold': 0.25950549077026314}\n",
      "model#:  45\n",
      "performance:  [0.8519999861717225, 0.9310107827186584, 0.8724532296049323, 0.7995270252227783]\n",
      "parameter_set:  {'vector_size': 72, 'context_window': 8, 'min_count': 4, 'epochs': 13, 'dim': 247, 'padding': 'pre', 'learning_rate': 0.015249192133183027, 'dropout': 0.3652738620129109, 'threshold': 0.41109764969595985}\n",
      "model#:  46\n",
      "performance:  [0.871999990940094, 0.8330928325653076, 0.8699907103049401, 0.9003431916236877]\n",
      "parameter_set:  {'vector_size': 90, 'context_window': 7, 'min_count': 4, 'epochs': 9, 'dim': 242, 'padding': 'post', 'learning_rate': 0.017366795357882134, 'dropout': 0.1546986556229471, 'threshold': 0.6113280471201261}\n",
      "model#:  47\n",
      "performance:  [0.8700000047683716, 0.8711743235588074, 0.8482513711729271, 0.862913191318512]\n",
      "parameter_set:  {'vector_size': 60, 'context_window': 7, 'min_count': 4, 'epochs': 6, 'dim': 211, 'padding': 'pre', 'learning_rate': 0.06940099325284274, 'dropout': 0.5570597877878822, 'threshold': 0.42363894347549486}\n",
      "model#:  53\n",
      "performance:  [0.8039999961853027, 0.9587439060211181, 0.8623385051420096, 0.72792067527771]\n",
      "parameter_set:  {'vector_size': 83, 'context_window': 5, 'min_count': 4, 'epochs': 12, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.024914324150988945, 'dropout': 0.3266837646724929, 'threshold': 0.23028018057396393}\n",
      "model#:  54\n",
      "performance:  [0.7140000104904175, 0.975290322303772, 0.8705531942314609, 0.6350682258605957]\n",
      "parameter_set:  {'vector_size': 65, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 250, 'padding': 'pre', 'learning_rate': 0.022362502284241123, 'dropout': 0.6825986278911025, 'threshold': 0.22085158109556471}\n",
      "model#:  60\n",
      "performance:  [0.877999997138977, 0.9008589267730713, 0.880663200614846, 0.8570821404457092]\n",
      "parameter_set:  {'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 248, 'padding': 'pre', 'learning_rate': 0.008076709312390297, 'dropout': 0.45592506038880143, 'threshold': 0.5188836233727432}\n",
      "model#:  61\n",
      "performance:  [0.7340000033378601, 0.4676465272903442, 0.8712232779273394, 0.9577777743339538]\n",
      "parameter_set:  {'vector_size': 90, 'context_window': 9, 'min_count': 6, 'epochs': 11, 'dim': 249, 'padding': 'pre', 'learning_rate': 0.0012770082360575726, 'dropout': 0.3530509104242916, 'threshold': 0.7677871886007199}\n",
      "model#:  62\n",
      "performance:  [0.8860000014305115, 0.8685741782188415, 0.8685768883215692, 0.8966945052146912]\n",
      "parameter_set:  {'vector_size': 57, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 248, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.3035608419348366, 'threshold': 0.598413172203673}\n",
      "model#:  63\n",
      "performance:  [0.8379999995231628, 0.9387356519699097, 0.8847707965556909, 0.7752236485481262]\n",
      "parameter_set:  {'vector_size': 59, 'context_window': 9, 'min_count': 4, 'epochs': 10, 'dim': 215, 'padding': 'post', 'learning_rate': 0.003010549526514929, 'dropout': 0.29111196902654446, 'threshold': 0.38596924952349143}\n",
      "model#:  67\n",
      "performance:  [0.8639999985694885, 0.809978699684143, 0.8618271996305081, 0.9048617839813232]\n",
      "parameter_set:  {'vector_size': 60, 'context_window': 7, 'min_count': 4, 'epochs': 6, 'dim': 231, 'padding': 'pre', 'learning_rate': 0.03176099025801702, 'dropout': 0.5570597877878822, 'threshold': 0.5848579651306551}\n",
      "model#:  70\n",
      "performance:  [0.771999990940094, 0.9715866208076477, 0.8731890758127022, 0.6889812469482421]\n",
      "parameter_set:  {'vector_size': 65, 'context_window': 7, 'min_count': 4, 'epochs': 11, 'dim': 213, 'padding': 'pre', 'learning_rate': 0.00498923582605686, 'dropout': 0.35378940532177783, 'threshold': 0.22085158109556471}\n",
      "model#:  71\n",
      "performance:  [0.8660000085830688, 0.920496118068695, 0.855985334105816, 0.8254461526870728]\n",
      "parameter_set:  {'vector_size': 97, 'context_window': 7, 'min_count': 4, 'epochs': 7, 'dim': 241, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.2641612479032547, 'threshold': 0.39668687769047273}\n",
      "model#:  74\n",
      "performance:  [0.8460000038146973, 0.9421823620796204, 0.8653977975588024, 0.7838133573532104]\n",
      "parameter_set:  {'vector_size': 58, 'context_window': 9, 'min_count': 4, 'epochs': 12, 'dim': 236, 'padding': 'pre', 'learning_rate': 0.013837338558726611, 'dropout': 0.3688788521871006, 'threshold': 0.33112727656309526}\n",
      "model#:  75\n",
      "performance:  [0.8600000023841858, 0.8128660798072815, 0.8793577735989906, 0.8956371426582337]\n",
      "parameter_set:  {'vector_size': 63, 'context_window': 9, 'min_count': 4, 'epochs': 13, 'dim': 220, 'padding': 'post', 'learning_rate': 0.06940099325284274, 'dropout': 0.2937001266043564, 'threshold': 0.626312425986365}\n",
      "model#:  76\n",
      "performance:  [0.8679999947547913, 0.803175973892212, 0.8726098754735286, 0.9154129147529602]\n",
      "parameter_set:  {'vector_size': 69, 'context_window': 6, 'min_count': 6, 'epochs': 14, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.6127060603215981}\n",
      "model#:  77\n",
      "performance:  [0.8639999985694885, 0.9181007266044616, 0.8743806385281635, 0.8255503177642822]\n",
      "parameter_set:  {'vector_size': 60, 'context_window': 7, 'min_count': 4, 'epochs': 7, 'dim': 219, 'padding': 'pre', 'learning_rate': 0.06940099325284274, 'dropout': 0.2641612479032547, 'threshold': 0.39668687769047273}\n",
      "model#:  78\n",
      "performance:  [0.8220000028610229, 0.9541496515274048, 0.8640757698742144, 0.748492443561554]\n",
      "parameter_set:  {'vector_size': 85, 'context_window': 5, 'min_count': 6, 'epochs': 13, 'dim': 216, 'padding': 'post', 'learning_rate': 0.072924851646279, 'dropout': 0.20727923139416127, 'threshold': 0.25950549077026314}\n",
      "model#:  79\n",
      "performance:  [0.722000002861023, 0.9840514063835144, 0.8601334346430365, 0.6401177287101746]\n",
      "parameter_set:  {'vector_size': 72, 'context_window': 5, 'min_count': 4, 'epochs': 11, 'dim': 247, 'padding': 'post', 'learning_rate': 0.0047066467461851485, 'dropout': 0.6064450125924121, 'threshold': 0.22824384026433708}\n",
      "model#:  81\n",
      "performance:  [0.8420000076293945, 0.7439950585365296, 0.8737075185365084, 0.9190223217010498]\n",
      "parameter_set:  {'vector_size': 78, 'context_window': 5, 'min_count': 4, 'epochs': 12, 'dim': 241, 'padding': 'pre', 'learning_rate': 0.01033647175166428, 'dropout': 0.5993483227346456, 'threshold': 0.648690599350557}\n",
      "model#:  84\n",
      "performance:  [0.8419999957084656, 0.7382903814315795, 0.855104913352968, 0.9221868753433228]\n",
      "parameter_set:  {'vector_size': 85, 'context_window': 5, 'min_count': 6, 'epochs': 13, 'dim': 232, 'padding': 'pre', 'learning_rate': 0.019718734867748347, 'dropout': 0.27571155440689404, 'threshold': 0.722286519136603}\n",
      "model#:  87\n",
      "performance:  [0.8480000138282776, 0.735411274433136, 0.8730671201216831, 0.937587833404541]\n",
      "parameter_set:  {'vector_size': 80, 'context_window': 9, 'min_count': 4, 'epochs': 12, 'dim': 218, 'padding': 'pre', 'learning_rate': 0.013837338558726611, 'dropout': 0.3688788521871006, 'threshold': 0.7124538155936133}\n",
      "model#:  93\n",
      "performance:  [0.5159999907016755, 1.0, 0.7131789275462885, 0.5035043895244599]\n",
      "parameter_set:  {'vector_size': 72, 'context_window': 4, 'min_count': 6, 'epochs': 8, 'dim': 247, 'padding': 'pre', 'learning_rate': 0.00041035703969044996, 'dropout': 0.6064450125924121, 'threshold': 0.3508595938250224}\n",
      "model#:  94\n",
      "performance:  [0.8699999928474427, 0.876359510421753, 0.8664884199709821, 0.8601428270339966]\n",
      "parameter_set:  {'vector_size': 89, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.008200999065076656, 'dropout': 0.2368719869678908, 'threshold': 0.49106574275893305}\n",
      "model#:  95\n",
      "performance:  [0.8459999918937683, 0.9553425312042236, 0.8613765492554084, 0.782619035243988]\n",
      "parameter_set:  {'vector_size': 88, 'context_window': 9, 'min_count': 6, 'epochs': 9, 'dim': 245, 'padding': 'post', 'learning_rate': 0.05659002800626353, 'dropout': 0.29781604475585965, 'threshold': 0.3349786355102691}\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "for i in study_pure.best_trials:\n",
    "    print('model#: ', i.number)\n",
    "    print('performance: ', i.values)\n",
    "    print('parameter_set: ', i.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_df = study_pure.trials_dataframe()\n",
    "pure_df = pure_df.rename(columns=({'values_0': 'accuracy', 'values_1': 'recall', 'values_2': 'f1', 'values_3': 'precison'}))\n",
    "pure_df.to_json('data/hyperparameter_search/pure_embedding.json')\n",
    "\n",
    "joblib.dump(study_pure, 'data/hyperparameter_search/pure_embedding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_from_disk = joblib.load('data/hyperparameter_search/pure_embedding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model#:  1\n",
      "performance:  [0.37018485069274903, 0.8480000019073486, 0.9172630667686462, 0.884265398979187]\n",
      "parameter_set:  {'vector_size': 95, 'context_window': 9, 'min_count': 4, 'epochs': 8, 'dim': 224, 'padding': 'pre', 'learning_rate': 0.013121832123684417, 'dropout': 0.4402980193837679, 'threshold': 0.5099871650242483}\n",
      "model#:  4\n",
      "performance:  [0.4063465356826782, 0.8580000042915344, 0.913949716091156, 0.8936826527118683]\n",
      "parameter_set:  {'vector_size': 98, 'context_window': 8, 'min_count': 4, 'epochs': 7, 'dim': 217, 'padding': 'pre', 'learning_rate': 0.002104272243300588, 'dropout': 0.5665904244287674, 'threshold': 0.4837522534769876}\n",
      "model#:  16\n",
      "performance:  [0.37377700209617615, 0.6839999914169311, 0.9236754536628723, 0.8780072510242463]\n",
      "parameter_set:  {'vector_size': 67, 'context_window': 6, 'min_count': 4, 'epochs': 10, 'dim': 253, 'padding': 'pre', 'learning_rate': 0.006558954145842335, 'dropout': 0.3398679639334519, 'threshold': 0.1592588728061565}\n",
      "model#:  18\n",
      "performance:  [0.36640002727508547, 0.7900000095367432, 0.9228288412094117, 0.8790714144706726]\n",
      "parameter_set:  {'vector_size': 92, 'context_window': 6, 'min_count': 5, 'epochs': 8, 'dim': 225, 'padding': 'post', 'learning_rate': 0.0041813177460875255, 'dropout': 0.12350836341987347, 'threshold': 0.268158450418295}\n",
      "model#:  19\n",
      "performance:  [0.3840878367424011, 0.8359999895095825, 0.9193294286727905, 0.8861442327499389]\n",
      "parameter_set:  {'vector_size': 69, 'context_window': 6, 'min_count': 4, 'epochs': 12, 'dim': 224, 'padding': 'pre', 'learning_rate': 0.006583549711521289, 'dropout': 0.5315205367359261, 'threshold': 0.438581478503552}\n",
      "model#:  33\n",
      "performance:  [0.36870052814483645, 0.8340000033378601, 0.923000967502594, 0.8828160405158997]\n",
      "parameter_set:  {'vector_size': 100, 'context_window': 9, 'min_count': 6, 'epochs': 7, 'dim': 226, 'padding': 'post', 'learning_rate': 0.003381911541796659, 'dropout': 0.17348567008380944, 'threshold': 0.4211814391704387}\n",
      "model#:  35\n",
      "performance:  [0.37887209057807925, 0.8439999938011169, 0.9253768801689148, 0.8692853093147278]\n",
      "parameter_set:  {'vector_size': 65, 'context_window': 6, 'min_count': 5, 'epochs': 13, 'dim': 218, 'padding': 'post', 'learning_rate': 0.06869955886137863, 'dropout': 0.34577165965031276, 'threshold': 0.515253888843372}\n",
      "model#:  47\n",
      "performance:  [0.37274417877197263, 0.8260000109672546, 0.9205412983894348, 0.8837137818336487]\n",
      "parameter_set:  {'vector_size': 75, 'context_window': 8, 'min_count': 6, 'epochs': 11, 'dim': 210, 'padding': 'post', 'learning_rate': 0.0070732476828858385, 'dropout': 0.5732955043287284, 'threshold': 0.39609778878727775}\n",
      "model#:  56\n",
      "performance:  [0.36992518305778505, 0.8439999938011169, 0.919501805305481, 0.8775018453598022]\n",
      "parameter_set:  {'vector_size': 95, 'context_window': 8, 'min_count': 5, 'epochs': 11, 'dim': 251, 'padding': 'post', 'learning_rate': 0.03307038679132375, 'dropout': 0.6083609533426858, 'threshold': 0.4615725188128157}\n",
      "model#:  64\n",
      "performance:  [0.39497090578079225, 0.7640000104904174, 0.9153204321861267, 0.8899289429187774]\n",
      "parameter_set:  {'vector_size': 78, 'context_window': 8, 'min_count': 6, 'epochs': 12, 'dim': 236, 'padding': 'pre', 'learning_rate': 0.0044363682018964635, 'dropout': 0.6095482871294909, 'threshold': 0.2973586768968908}\n",
      "model#:  68\n",
      "performance:  [0.36395630836486814, 0.85, 0.9240322947502136, 0.8733632504940033]\n",
      "parameter_set:  {'vector_size': 92, 'context_window': 9, 'min_count': 6, 'epochs': 8, 'dim': 224, 'padding': 'pre', 'learning_rate': 0.013121832123684417, 'dropout': 0.4402980193837679, 'threshold': 0.5099871650242483}\n",
      "model#:  69\n",
      "performance:  [0.4057378053665161, 0.800000011920929, 0.9075042605400085, 0.8869382083415985]\n",
      "parameter_set:  {'vector_size': 99, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 210, 'padding': 'post', 'learning_rate': 0.0036230436593560032, 'dropout': 0.5732955043287284, 'threshold': 0.39609778878727775}\n",
      "model#:  70\n",
      "performance:  [0.37281436324119566, 0.8360000014305115, 0.9190852046012878, 0.879884272813797]\n",
      "parameter_set:  {'vector_size': 85, 'context_window': 6, 'min_count': 5, 'epochs': 12, 'dim': 260, 'padding': 'post', 'learning_rate': 0.006583549711521289, 'dropout': 0.30534808791281326, 'threshold': 0.438581478503552}\n",
      "model#:  71\n",
      "performance:  [0.36974825263023375, 0.7899999976158142, 0.9230389475822449, 0.880963397026062]\n",
      "parameter_set:  {'vector_size': 95, 'context_window': 9, 'min_count': 5, 'epochs': 8, 'dim': 236, 'padding': 'pre', 'learning_rate': 0.031585542746709556, 'dropout': 0.4402980193837679, 'threshold': 0.2973586768968908}\n",
      "model#:  72\n",
      "performance:  [0.3766344964504242, 0.7299999952316284, 0.922268009185791, 0.8846936821937561]\n",
      "parameter_set:  {'vector_size': 100, 'context_window': 8, 'min_count': 6, 'epochs': 12, 'dim': 214, 'padding': 'pre', 'learning_rate': 0.006583549711521289, 'dropout': 0.5315205367359261, 'threshold': 0.20472761439357615}\n",
      "model#:  75\n",
      "performance:  [0.37591999769210815, 0.8259999990463257, 0.9256234645843506, 0.884514719247818]\n",
      "parameter_set:  {'vector_size': 92, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 240, 'padding': 'post', 'learning_rate': 0.05319215985369705, 'dropout': 0.2789697007490909, 'threshold': 0.37478732958317484}\n",
      "model#:  77\n",
      "performance:  [0.38652572631835935, 0.7100000023841858, 0.9192495822906495, 0.8872414648532867]\n",
      "parameter_set:  {'vector_size': 80, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 225, 'padding': 'pre', 'learning_rate': 0.021865918005691456, 'dropout': 0.6543694936191573, 'threshold': 0.18252706214288847}\n",
      "model#:  84\n",
      "performance:  [0.345776230096817, 0.8399999976158142, 0.9290870070457459, 0.8774502992630004]\n",
      "parameter_set:  {'vector_size': 100, 'context_window': 6, 'min_count': 5, 'epochs': 7, 'dim': 234, 'padding': 'post', 'learning_rate': 0.041612208476163974, 'dropout': 0.19861199933757845, 'threshold': 0.4211814391704387}\n",
      "model#:  97\n",
      "performance:  [0.3662318825721741, 0.65, 0.9267548322677612, 0.88543341755867]\n",
      "parameter_set:  {'vector_size': 59, 'context_window': 8, 'min_count': 6, 'epochs': 11, 'dim': 253, 'padding': 'pre', 'learning_rate': 0.03307038679132375, 'dropout': 0.5254487531463705, 'threshold': 0.10667870810226035}\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "for i in study_pure.best_trials:\n",
    "    print('model#: ', i.number)\n",
    "    print('performance: ', i.values)\n",
    "    print('parameter_set: ', i.params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Embedding + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-09-08 10:13:42,804]\u001b[0m A new study created in memory with name: embedding_cnn\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-09-08 10:27:06,115]\u001b[0m Trial 0 finished with values: [0.7840000033378601, 0.7426276206970215, 0.7697428192257428, 0.8223498225212097] and parameters: {'vector_size': 34, 'context_window': 9, 'min_count': 4, 'epochs': 6, 'dim': 358, 'padding': 'pre', 'learning_rate': 0.010714528771518971, 'dropout': 0.6535637196987211, 'filter': 30, 'kernel': 12, 'regularizer': 0.015112953378004324}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 10:40:11,720]\u001b[0m Trial 1 finished with values: [0.8560000061988831, 0.8530639767646789, 0.8523795728960095, 0.8540852665901184] and parameters: {'vector_size': 90, 'context_window': 10, 'min_count': 3, 'epochs': 6, 'dim': 225, 'padding': 'pre', 'learning_rate': 0.000944635755123106, 'dropout': 0.36577222193378545, 'filter': 13, 'kernel': 8, 'regularizer': 2.3799437817752373e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 10:52:01,588]\u001b[0m Trial 2 finished with values: [0.8020000219345093, 0.795356285572052, 0.7733935361223606, 0.8121090173721314] and parameters: {'vector_size': 27, 'context_window': 10, 'min_count': 2, 'epochs': 11, 'dim': 251, 'padding': 'post', 'learning_rate': 0.015506265995074372, 'dropout': 0.23199359592295365, 'filter': 16, 'kernel': 14, 'regularizer': 0.577635515351027}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 11:09:21,256]\u001b[0m Trial 3 finished with values: [0.8580000042915344, 0.8526723146438598, 0.8521159118230498, 0.8536665439605713] and parameters: {'vector_size': 62, 'context_window': 6, 'min_count': 6, 'epochs': 11, 'dim': 374, 'padding': 'pre', 'learning_rate': 0.0010128230299229876, 'dropout': 0.4731857780684591, 'filter': 61, 'kernel': 8, 'regularizer': 0.01774616118977074}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 11:17:52,220]\u001b[0m Trial 4 finished with values: [0.8279999971389771, 0.8310767531394958, 0.8232543252605227, 0.8167506933212281] and parameters: {'vector_size': 46, 'context_window': 4, 'min_count': 10, 'epochs': 7, 'dim': 164, 'padding': 'post', 'learning_rate': 0.00017134453568884504, 'dropout': 0.31909360935229736, 'filter': 49, 'kernel': 19, 'regularizer': 0.0008756928320959522}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 11:30:33,415]\u001b[0m Trial 5 finished with values: [0.8379999995231628, 0.8344025254249573, 0.8330406496804734, 0.832440984249115] and parameters: {'vector_size': 33, 'context_window': 8, 'min_count': 2, 'epochs': 12, 'dim': 260, 'padding': 'post', 'learning_rate': 0.0003033941425599605, 'dropout': 0.5657219568674208, 'filter': 58, 'kernel': 5, 'regularizer': 0.0011295400360378668}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 11:42:16,693]\u001b[0m Trial 6 finished with values: [0.8400000095367431, 0.8516580700874329, 0.8380807205025729, 0.8284589648246765] and parameters: {'vector_size': 73, 'context_window': 3, 'min_count': 5, 'epochs': 14, 'dim': 154, 'padding': 'pre', 'learning_rate': 0.0017222305392010438, 'dropout': 0.25958863409319116, 'filter': 49, 'kernel': 14, 'regularizer': 0.001007140599328687}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 12:06:52,789]\u001b[0m Trial 7 finished with values: [0.7019999980926513, 0.634359921514988, 0.6252722347169378, 0.7403102874755859] and parameters: {'vector_size': 90, 'context_window': 10, 'min_count': 3, 'epochs': 12, 'dim': 264, 'padding': 'post', 'learning_rate': 0.033429228467036144, 'dropout': 0.14547170849440055, 'filter': 44, 'kernel': 18, 'regularizer': 0.8813687551450168}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 12:17:35,271]\u001b[0m Trial 8 finished with values: [0.8199999928474426, 0.8420339584350586, 0.8199577572964669, 0.80261732339859] and parameters: {'vector_size': 85, 'context_window': 8, 'min_count': 2, 'epochs': 6, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00018456185181440522, 'dropout': 0.4059693037775741, 'filter': 9, 'kernel': 17, 'regularizer': 0.014851429603271972}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 12:27:43,905]\u001b[0m Trial 9 finished with values: [0.8460000038146973, 0.8581447243690491, 0.843333276542442, 0.8366020202636719] and parameters: {'vector_size': 70, 'context_window': 2, 'min_count': 9, 'epochs': 9, 'dim': 189, 'padding': 'pre', 'learning_rate': 0.00046193452693710983, 'dropout': 0.25172581727979687, 'filter': 44, 'kernel': 11, 'regularizer': 0.0314575010612245}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 12:43:41,638]\u001b[0m Trial 10 finished with values: [0.771999990940094, 0.7028200387954712, 0.7466592302292087, 0.8009647965431214] and parameters: {'vector_size': 66, 'context_window': 4, 'min_count': 7, 'epochs': 14, 'dim': 378, 'padding': 'post', 'learning_rate': 0.08927998400747972, 'dropout': 0.2834983575679978, 'filter': 11, 'kernel': 14, 'regularizer': 0.007633030635878238}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 12:52:07,526]\u001b[0m Trial 11 finished with values: [0.793999993801117, 0.7906383514404297, 0.78576568411664, 0.7847714900970459] and parameters: {'vector_size': 35, 'context_window': 10, 'min_count': 5, 'epochs': 13, 'dim': 356, 'padding': 'post', 'learning_rate': 0.00014124014136325118, 'dropout': 0.6130348045537208, 'filter': 21, 'kernel': 3, 'regularizer': 6.261025385887828e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 13:01:19,354]\u001b[0m Trial 12 finished with values: [0.8399999976158142, 0.8604713916778565, 0.8396634570161853, 0.820673656463623] and parameters: {'vector_size': 47, 'context_window': 5, 'min_count': 8, 'epochs': 12, 'dim': 283, 'padding': 'post', 'learning_rate': 0.0020683013054382813, 'dropout': 0.15494280681726422, 'filter': 17, 'kernel': 7, 'regularizer': 0.0037346553650350603}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 13:12:58,077]\u001b[0m Trial 13 finished with values: [0.8160000085830689, 0.8341744065284729, 0.8156723660777541, 0.7995179414749145] and parameters: {'vector_size': 97, 'context_window': 12, 'min_count': 3, 'epochs': 6, 'dim': 409, 'padding': 'post', 'learning_rate': 0.00047014620761051586, 'dropout': 0.2425025378135165, 'filter': 24, 'kernel': 5, 'regularizer': 3.1263436154905014e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 13:23:08,836]\u001b[0m Trial 14 finished with values: [0.7660000085830688, 0.7285466909408569, 0.7489187476405175, 0.7770103454589844] and parameters: {'vector_size': 34, 'context_window': 4, 'min_count': 1, 'epochs': 14, 'dim': 237, 'padding': 'pre', 'learning_rate': 0.012492933533543188, 'dropout': 0.1962123914826766, 'filter': 8, 'kernel': 16, 'regularizer': 1.5932189119542573e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 13:31:16,166]\u001b[0m Trial 15 finished with values: [0.8399999976158142, 0.8478114485740662, 0.83822495895515, 0.8301575064659119] and parameters: {'vector_size': 24, 'context_window': 6, 'min_count': 6, 'epochs': 11, 'dim': 406, 'padding': 'pre', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 64, 'kernel': 3, 'regularizer': 0.49787873612648437}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 13:37:54,111]\u001b[0m Trial 16 finished with values: [0.806000006198883, 0.8522627711296081, 0.8104883452306506, 0.7728230953216553] and parameters: {'vector_size': 73, 'context_window': 2, 'min_count': 8, 'epochs': 12, 'dim': 97, 'padding': 'post', 'learning_rate': 0.003541111272384803, 'dropout': 0.26669217760784036, 'filter': 5, 'kernel': 6, 'regularizer': 0.003267745613032898}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 13:54:54,737]\u001b[0m Trial 17 finished with values: [0.8620000004768371, 0.8820380687713623, 0.8598337299053881, 0.8401095151901246] and parameters: {'vector_size': 89, 'context_window': 5, 'min_count': 4, 'epochs': 14, 'dim': 342, 'padding': 'post', 'learning_rate': 0.00038670412966838717, 'dropout': 0.2577446490172732, 'filter': 30, 'kernel': 11, 'regularizer': 0.09006028534412477}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 14:14:24,383]\u001b[0m Trial 18 finished with values: [0.8100000023841858, 0.7606788992881774, 0.795114581321939, 0.8336262583732605] and parameters: {'vector_size': 84, 'context_window': 11, 'min_count': 10, 'epochs': 10, 'dim': 428, 'padding': 'post', 'learning_rate': 0.07588415889006056, 'dropout': 0.5856506609694209, 'filter': 30, 'kernel': 16, 'regularizer': 0.0042725702285393895}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 14:23:17,467]\u001b[0m Trial 19 finished with values: [0.7800000071525574, 0.7759568572044373, 0.7723693820062257, 0.77005455493927] and parameters: {'vector_size': 38, 'context_window': 12, 'min_count': 10, 'epochs': 12, 'dim': 253, 'padding': 'pre', 'learning_rate': 0.0002190541936615257, 'dropout': 0.26772997771076434, 'filter': 9, 'kernel': 14, 'regularizer': 0.01768187438960066}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 14:31:07,752]\u001b[0m Trial 20 finished with values: [0.8380000114440918, 0.8723630905151367, 0.83834793078146, 0.8085974931716919] and parameters: {'vector_size': 67, 'context_window': 4, 'min_count': 10, 'epochs': 12, 'dim': 262, 'padding': 'post', 'learning_rate': 0.0008348939537165743, 'dropout': 0.674718047954647, 'filter': 6, 'kernel': 4, 'regularizer': 0.00011884604485298875}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 14:35:44,610]\u001b[0m Trial 21 finished with values: [0.7620000004768371, 0.7149330019950867, 0.7308195599998447, 0.8162111282348633] and parameters: {'vector_size': 95, 'context_window': 3, 'min_count': 4, 'epochs': 6, 'dim': 187, 'padding': 'post', 'learning_rate': 0.0025889938927600165, 'dropout': 0.2689607706537767, 'filter': 19, 'kernel': 1, 'regularizer': 0.32703465772561185}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 14:41:07,568]\u001b[0m Trial 22 finished with values: [0.806000006198883, 0.8157781839370728, 0.8022020174399174, 0.7909868836402894] and parameters: {'vector_size': 43, 'context_window': 10, 'min_count': 10, 'epochs': 6, 'dim': 362, 'padding': 'pre', 'learning_rate': 0.012078458058531227, 'dropout': 0.5575100826813773, 'filter': 29, 'kernel': 1, 'regularizer': 0.00042072975091135973}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 14:53:42,769]\u001b[0m Trial 23 finished with values: [0.8379999995231628, 0.8699429631233215, 0.8394037211334618, 0.8138328671455384] and parameters: {'vector_size': 28, 'context_window': 12, 'min_count': 10, 'epochs': 13, 'dim': 385, 'padding': 'pre', 'learning_rate': 0.000515862761572847, 'dropout': 0.5823769006688225, 'filter': 44, 'kernel': 13, 'regularizer': 0.003383834788259656}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 14:58:28,068]\u001b[0m Trial 24 finished with values: [0.8, 0.7989720344543457, 0.7955260725871439, 0.7933207750320435] and parameters: {'vector_size': 14, 'context_window': 7, 'min_count': 7, 'epochs': 9, 'dim': 92, 'padding': 'post', 'learning_rate': 0.003810440671725004, 'dropout': 0.33103862270409157, 'filter': 55, 'kernel': 3, 'regularizer': 0.006415257528948268}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 15:07:48,928]\u001b[0m Trial 25 finished with values: [0.6720000028610229, 0.5911922015249729, 0.5396603647067861, 0.8174572706222534] and parameters: {'vector_size': 22, 'context_window': 7, 'min_count': 2, 'epochs': 13, 'dim': 137, 'padding': 'post', 'learning_rate': 0.016879682233052685, 'dropout': 0.1765900781870594, 'filter': 56, 'kernel': 17, 'regularizer': 0.6213224342747183}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 15:12:29,097]\u001b[0m Trial 26 finished with values: [0.8019999861717224, 0.7943324327468873, 0.7978032225717206, 0.8053013801574707] and parameters: {'vector_size': 28, 'context_window': 3, 'min_count': 8, 'epochs': 9, 'dim': 52, 'padding': 'pre', 'learning_rate': 0.0013454244254979797, 'dropout': 0.1658310735775031, 'filter': 26, 'kernel': 12, 'regularizer': 0.08396921872796524}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 15:36:19,270]\u001b[0m Trial 27 finished with values: [0.8480000019073486, 0.858745276927948, 0.8462719286225753, 0.8356193900108337] and parameters: {'vector_size': 92, 'context_window': 7, 'min_count': 10, 'epochs': 9, 'dim': 201, 'padding': 'pre', 'learning_rate': 0.04850222404839205, 'dropout': 0.35631969545026576, 'filter': 64, 'kernel': 15, 'regularizer': 0.0006865206485370288}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 15:42:50,075]\u001b[0m Trial 28 finished with values: [0.8159999847412109, 0.8380278944969177, 0.8167149723003237, 0.7989605784416198] and parameters: {'vector_size': 30, 'context_window': 2, 'min_count': 7, 'epochs': 14, 'dim': 162, 'padding': 'pre', 'learning_rate': 0.004998746010380239, 'dropout': 0.243329887467928, 'filter': 38, 'kernel': 2, 'regularizer': 1.2289609094604781e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:00:27,816]\u001b[0m Trial 29 finished with values: [0.8240000009536743, 0.8497615694999695, 0.8227797767012627, 0.7985029697418213] and parameters: {'vector_size': 43, 'context_window': 5, 'min_count': 7, 'epochs': 9, 'dim': 296, 'padding': 'pre', 'learning_rate': 0.0017726900507043614, 'dropout': 0.23793280144694814, 'filter': 55, 'kernel': 18, 'regularizer': 6.259176578549006e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:07:57,017]\u001b[0m Trial 30 finished with values: [0.7980000019073487, 0.8057417631149292, 0.7929827397535849, 0.7867475748062134] and parameters: {'vector_size': 30, 'context_window': 9, 'min_count': 7, 'epochs': 7, 'dim': 140, 'padding': 'pre', 'learning_rate': 0.010290924307298716, 'dropout': 0.6565355100393362, 'filter': 61, 'kernel': 14, 'regularizer': 1.929335876687806e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:17:46,246]\u001b[0m Trial 31 finished with values: [0.8340000033378601, 0.8133567094802856, 0.8259325798602042, 0.8431530714035034] and parameters: {'vector_size': 76, 'context_window': 4, 'min_count': 6, 'epochs': 10, 'dim': 405, 'padding': 'pre', 'learning_rate': 0.0005244984449713138, 'dropout': 0.4989385925187537, 'filter': 5, 'kernel': 6, 'regularizer': 0.00043769915312465374}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:21:55,413]\u001b[0m Trial 32 finished with values: [0.8340000033378601, 0.8369092345237732, 0.830855180289355, 0.8254912376403809] and parameters: {'vector_size': 32, 'context_window': 12, 'min_count': 7, 'epochs': 6, 'dim': 122, 'padding': 'pre', 'learning_rate': 0.0047940155614857585, 'dropout': 0.38131761767696193, 'filter': 42, 'kernel': 4, 'regularizer': 0.0007934634314305388}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:32:24,596]\u001b[0m Trial 33 finished with values: [0.8119999885559082, 0.8180485129356384, 0.809259772927559, 0.8051836609840393] and parameters: {'vector_size': 17, 'context_window': 2, 'min_count': 3, 'epochs': 10, 'dim': 336, 'padding': 'post', 'learning_rate': 0.016280496480239992, 'dropout': 0.4145340043531194, 'filter': 62, 'kernel': 18, 'regularizer': 0.0786478270592816}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:44:22,818]\u001b[0m Trial 34 finished with values: [0.8, 0.7965931415557861, 0.7931841689079195, 0.7911247491836548] and parameters: {'vector_size': 64, 'context_window': 3, 'min_count': 3, 'epochs': 12, 'dim': 251, 'padding': 'pre', 'learning_rate': 0.00011548276089319608, 'dropout': 0.4077702368656785, 'filter': 17, 'kernel': 13, 'regularizer': 0.013978523826805677}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:50:24,562]\u001b[0m Trial 35 finished with values: [0.7759999871253968, 0.752956771850586, 0.7650648535276179, 0.7818160772323608] and parameters: {'vector_size': 31, 'context_window': 12, 'min_count': 8, 'epochs': 10, 'dim': 76, 'padding': 'post', 'learning_rate': 0.0002806716009568495, 'dropout': 0.6052857941218505, 'filter': 47, 'kernel': 10, 'regularizer': 2.842782781634847e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 16:58:15,171]\u001b[0m Trial 36 finished with values: [0.7100000023841858, 0.761653259396553, 0.6862007808012088, 0.726097172498703] and parameters: {'vector_size': 64, 'context_window': 4, 'min_count': 6, 'epochs': 14, 'dim': 78, 'padding': 'pre', 'learning_rate': 0.015378025724762897, 'dropout': 0.5335528958801252, 'filter': 48, 'kernel': 16, 'regularizer': 0.8821917797774943}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 17:03:41,957]\u001b[0m Trial 37 finished with values: [0.8120000004768372, 0.8444238185882569, 0.8134637713270256, 0.7982164740562439] and parameters: {'vector_size': 34, 'context_window': 2, 'min_count': 8, 'epochs': 6, 'dim': 342, 'padding': 'pre', 'learning_rate': 0.0035642216730954294, 'dropout': 0.3191786652468964, 'filter': 15, 'kernel': 8, 'regularizer': 0.005268225958537679}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 17:09:46,305]\u001b[0m Trial 38 finished with values: [0.8299999952316284, 0.8347406029701233, 0.8264559052170147, 0.8201367855072021] and parameters: {'vector_size': 14, 'context_window': 8, 'min_count': 1, 'epochs': 11, 'dim': 96, 'padding': 'pre', 'learning_rate': 0.0007381370275233295, 'dropout': 0.4031314888394324, 'filter': 63, 'kernel': 10, 'regularizer': 0.0914355898201947}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 17:17:55,038]\u001b[0m Trial 39 finished with values: [0.7160000085830689, 0.6466556668281556, 0.684147449736298, 0.7508719444274903] and parameters: {'vector_size': 94, 'context_window': 6, 'min_count': 10, 'epochs': 14, 'dim': 124, 'padding': 'post', 'learning_rate': 0.045026828387272524, 'dropout': 0.11456615185513218, 'filter': 23, 'kernel': 6, 'regularizer': 1.2168342844085188e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 17:23:29,569]\u001b[0m Trial 40 finished with values: [0.7539999902248382, 0.6662131547927856, 0.6584885439763488, 0.6569966793060302] and parameters: {'vector_size': 26, 'context_window': 2, 'min_count': 7, 'epochs': 14, 'dim': 179, 'padding': 'post', 'learning_rate': 0.04227164261420291, 'dropout': 0.6997095759777722, 'filter': 26, 'kernel': 1, 'regularizer': 0.2785046637270679}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 17:31:26,275]\u001b[0m Trial 41 finished with values: [0.8179999947547912, 0.8217316031455993, 0.815828981964221, 0.8141100645065308] and parameters: {'vector_size': 48, 'context_window': 3, 'min_count': 9, 'epochs': 12, 'dim': 309, 'padding': 'post', 'learning_rate': 0.002008567149888518, 'dropout': 0.11686721219091484, 'filter': 6, 'kernel': 7, 'regularizer': 0.00410332106124999}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 17:43:18,312]\u001b[0m Trial 42 finished with values: [0.806000006198883, 0.8304253578186035, 0.8062082325475783, 0.7871749877929688] and parameters: {'vector_size': 71, 'context_window': 10, 'min_count': 10, 'epochs': 6, 'dim': 175, 'padding': 'post', 'learning_rate': 0.006776473819110473, 'dropout': 0.14424079161539996, 'filter': 55, 'kernel': 12, 'regularizer': 0.00017772106838793354}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 17:53:54,273]\u001b[0m Trial 43 finished with values: [0.7980000138282776, 0.8159568548202515, 0.7963500722176607, 0.7800499081611634] and parameters: {'vector_size': 43, 'context_window': 9, 'min_count': 3, 'epochs': 7, 'dim': 358, 'padding': 'pre', 'learning_rate': 0.00017459445995545773, 'dropout': 0.1603902872434407, 'filter': 46, 'kernel': 13, 'regularizer': 4.322864453287175e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:01:16,310]\u001b[0m Trial 44 finished with values: [0.7899999976158142, 0.7871036887168884, 0.7854700382236678, 0.7884778380393982] and parameters: {'vector_size': 20, 'context_window': 4, 'min_count': 3, 'epochs': 10, 'dim': 318, 'padding': 'pre', 'learning_rate': 0.00012946441462620534, 'dropout': 0.28634579110061054, 'filter': 29, 'kernel': 8, 'regularizer': 0.0004584260590537966}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:10:40,251]\u001b[0m Trial 45 finished with values: [0.7759999990463257, 0.826716148853302, 0.7853997310761794, 0.7866528153419494] and parameters: {'vector_size': 57, 'context_window': 3, 'min_count': 10, 'epochs': 7, 'dim': 238, 'padding': 'post', 'learning_rate': 0.020464554722562103, 'dropout': 0.25725224802352925, 'filter': 43, 'kernel': 19, 'regularizer': 0.08165609142696244}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:16:15,027]\u001b[0m Trial 46 finished with values: [0.7179999947547913, 0.6319879055023193, 0.6836950614656594, 0.756882905960083] and parameters: {'vector_size': 42, 'context_window': 2, 'min_count': 5, 'epochs': 12, 'dim': 124, 'padding': 'pre', 'learning_rate': 0.03421825895095091, 'dropout': 0.6830012292825461, 'filter': 36, 'kernel': 5, 'regularizer': 6.831246116914221e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:21:26,699]\u001b[0m Trial 47 finished with values: [0.7860000014305115, 0.8850161552429199, 0.8009057306546333, 0.7421926498413086] and parameters: {'vector_size': 76, 'context_window': 11, 'min_count': 10, 'epochs': 6, 'dim': 67, 'padding': 'post', 'learning_rate': 0.012056585059064229, 'dropout': 0.43787960332333575, 'filter': 32, 'kernel': 10, 'regularizer': 0.10717455796869138}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:36:23,701]\u001b[0m Trial 48 finished with values: [0.521999990940094, 0.22848072350025178, 0.2029072681704261, 0.28003663420677183] and parameters: {'vector_size': 75, 'context_window': 2, 'min_count': 6, 'epochs': 8, 'dim': 385, 'padding': 'post', 'learning_rate': 0.020306489482430717, 'dropout': 0.18971499103096204, 'filter': 23, 'kernel': 11, 'regularizer': 0.3533207090092147}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:44:44,355]\u001b[0m Trial 49 finished with values: [0.8539999961853028, 0.860336709022522, 0.8513506299345028, 0.8436973929405213] and parameters: {'vector_size': 37, 'context_window': 3, 'min_count': 2, 'epochs': 10, 'dim': 312, 'padding': 'post', 'learning_rate': 0.0019582143148307194, 'dropout': 0.2693847678313147, 'filter': 13, 'kernel': 9, 'regularizer': 0.004277818633924727}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:51:53,776]\u001b[0m Trial 50 finished with values: [0.8479999899864197, 0.8589733958244323, 0.8467349324066971, 0.8378621339797974] and parameters: {'vector_size': 36, 'context_window': 6, 'min_count': 10, 'epochs': 11, 'dim': 175, 'padding': 'pre', 'learning_rate': 0.00553324031182354, 'dropout': 0.14424079161539996, 'filter': 64, 'kernel': 3, 'regularizer': 0.00017772106838793354}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 18:57:17,597]\u001b[0m Trial 51 finished with values: [0.8019999861717224, 0.8314835429191589, 0.8032433954927309, 0.7804134488105774] and parameters: {'vector_size': 17, 'context_window': 2, 'min_count': 3, 'epochs': 6, 'dim': 358, 'padding': 'post', 'learning_rate': 0.016280496480239992, 'dropout': 0.4145340043531194, 'filter': 62, 'kernel': 3, 'regularizer': 0.015112953378004324}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:04:49,330]\u001b[0m Trial 52 finished with values: [0.7579999923706054, 0.7408630609512329, 0.7460691605256097, 0.752243971824646] and parameters: {'vector_size': 38, 'context_window': 3, 'min_count': 10, 'epochs': 12, 'dim': 253, 'padding': 'pre', 'learning_rate': 0.00011548276089319608, 'dropout': 0.26772997771076434, 'filter': 17, 'kernel': 9, 'regularizer': 0.013978523826805677}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:16:21,115]\u001b[0m Trial 53 finished with values: [0.8519999980926514, 0.8520208835601807, 0.8473332141367184, 0.8447115778923034] and parameters: {'vector_size': 28, 'context_window': 8, 'min_count': 1, 'epochs': 11, 'dim': 385, 'padding': 'pre', 'learning_rate': 0.000515862761572847, 'dropout': 0.5823769006688225, 'filter': 63, 'kernel': 10, 'regularizer': 0.003383834788259656}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:24:26,567]\u001b[0m Trial 54 finished with values: [0.8320000052452088, 0.8769106030464172, 0.835117222922961, 0.8103073835372925] and parameters: {'vector_size': 28, 'context_window': 11, 'min_count': 10, 'epochs': 10, 'dim': 192, 'padding': 'post', 'learning_rate': 0.0013454244254979797, 'dropout': 0.1658310735775031, 'filter': 26, 'kernel': 16, 'regularizer': 0.08396921872796524}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:31:53,238]\u001b[0m Trial 55 finished with values: [0.7960000038146973, 0.7011846423149108, 0.7559033145653149, 0.8880244016647338] and parameters: {'vector_size': 24, 'context_window': 6, 'min_count': 6, 'epochs': 12, 'dim': 309, 'padding': 'pre', 'learning_rate': 0.002008567149888518, 'dropout': 0.25961725113431555, 'filter': 64, 'kernel': 3, 'regularizer': 0.49787873612648437}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:39:20,231]\u001b[0m Trial 56 finished with values: [0.6999999940395355, 0.6137373752892017, 0.6110579925983852, 0.7896477341651916] and parameters: {'vector_size': 73, 'context_window': 11, 'min_count': 8, 'epochs': 12, 'dim': 97, 'padding': 'pre', 'learning_rate': 0.003541111272384803, 'dropout': 0.25961725113431555, 'filter': 5, 'kernel': 6, 'regularizer': 0.49787873612648437}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:46:19,739]\u001b[0m Trial 57 finished with values: [0.8379999876022339, 0.8771222472190857, 0.8402897290981827, 0.8075987577438355] and parameters: {'vector_size': 32, 'context_window': 12, 'min_count': 7, 'epochs': 12, 'dim': 122, 'padding': 'pre', 'learning_rate': 0.003541111272384803, 'dropout': 0.38131761767696193, 'filter': 41, 'kernel': 13, 'regularizer': 0.0007934634314305388}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:53:58,981]\u001b[0m Trial 58 finished with values: [0.8080000042915344, 0.8037353038787842, 0.8023627158037442, 0.8056245088577271] and parameters: {'vector_size': 20, 'context_window': 4, 'min_count': 3, 'epochs': 12, 'dim': 318, 'padding': 'pre', 'learning_rate': 0.00012946441462620534, 'dropout': 0.28634579110061054, 'filter': 29, 'kernel': 13, 'regularizer': 0.0004584260590537966}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 19:58:13,582]\u001b[0m Trial 59 finished with values: [0.8299999833106995, 0.8433408975601197, 0.8279974385228759, 0.8150771141052247] and parameters: {'vector_size': 14, 'context_window': 11, 'min_count': 1, 'epochs': 6, 'dim': 67, 'padding': 'pre', 'learning_rate': 0.0010436365397026002, 'dropout': 0.4031314888394324, 'filter': 63, 'kernel': 10, 'regularizer': 0.0036681265106424084}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 20:11:46,531]\u001b[0m Trial 60 finished with values: [0.8379999876022339, 0.8697478175163269, 0.838497622250023, 0.8121492385864257] and parameters: {'vector_size': 30, 'context_window': 3, 'min_count': 9, 'epochs': 12, 'dim': 296, 'padding': 'post', 'learning_rate': 0.002008567149888518, 'dropout': 0.23793280144694814, 'filter': 55, 'kernel': 18, 'regularizer': 6.259176578549006e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 20:28:58,180]\u001b[0m Trial 61 finished with values: [0.8520000219345093, 0.8777063131332398, 0.8517387015437817, 0.8306424856185913] and parameters: {'vector_size': 62, 'context_window': 6, 'min_count': 6, 'epochs': 10, 'dim': 374, 'padding': 'pre', 'learning_rate': 0.0005244984449713138, 'dropout': 0.4731857780684591, 'filter': 55, 'kernel': 8, 'regularizer': 0.01774616118977074}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 20:39:52,272]\u001b[0m Trial 62 finished with values: [0.8320000052452088, 0.8389349341392517, 0.8293714531283525, 0.8218036890029907] and parameters: {'vector_size': 34, 'context_window': 4, 'min_count': 3, 'epochs': 6, 'dim': 409, 'padding': 'pre', 'learning_rate': 0.00047014620761051586, 'dropout': 0.2425025378135165, 'filter': 24, 'kernel': 16, 'regularizer': 3.1263436154905014e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 20:46:10,021]\u001b[0m Trial 63 finished with values: [0.821999990940094, 0.8387906312942505, 0.8209548686346576, 0.8061793565750122] and parameters: {'vector_size': 14, 'context_window': 8, 'min_count': 1, 'epochs': 11, 'dim': 96, 'padding': 'pre', 'learning_rate': 0.0007381370275233295, 'dropout': 0.4031314888394324, 'filter': 63, 'kernel': 10, 'regularizer': 0.0914355898201947}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 20:57:44,641]\u001b[0m Trial 64 finished with values: [0.75, 0.7072232604026795, 0.7176367838459178, 0.7771235585212708] and parameters: {'vector_size': 46, 'context_window': 4, 'min_count': 10, 'epochs': 7, 'dim': 201, 'padding': 'post', 'learning_rate': 0.026511749857576133, 'dropout': 0.10927186138756739, 'filter': 64, 'kernel': 19, 'regularizer': 0.0006865206485370288}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 21:05:16,993]\u001b[0m Trial 65 finished with values: [0.7800000071525574, 0.7757012248039246, 0.7745194800456633, 0.7785721063613892] and parameters: {'vector_size': 36, 'context_window': 10, 'min_count': 5, 'epochs': 13, 'dim': 356, 'padding': 'post', 'learning_rate': 0.0003033941425599605, 'dropout': 0.43220791236734923, 'filter': 18, 'kernel': 3, 'regularizer': 0.0011295400360378668}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 21:09:14,700]\u001b[0m Trial 66 finished with values: [0.7960000038146973, 0.7745138525962829, 0.785217252523876, 0.8064395189285278] and parameters: {'vector_size': 73, 'context_window': 2, 'min_count': 7, 'epochs': 6, 'dim': 97, 'padding': 'post', 'learning_rate': 0.002725312714568801, 'dropout': 0.26669217760784036, 'filter': 5, 'kernel': 6, 'regularizer': 0.007633030635878238}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 21:17:44,571]\u001b[0m Trial 67 finished with values: [0.8539999961853028, 0.8631828427314758, 0.8524733833145047, 0.8450046062469483] and parameters: {'vector_size': 24, 'context_window': 6, 'min_count': 1, 'epochs': 11, 'dim': 406, 'padding': 'pre', 'learning_rate': 0.0007381370275233295, 'dropout': 0.4031314888394324, 'filter': 64, 'kernel': 3, 'regularizer': 0.0914355898201947}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 21:24:18,118]\u001b[0m Trial 68 finished with values: [0.8360000014305115, 0.8573806047439575, 0.8362582252174164, 0.8169460773468018] and parameters: {'vector_size': 14, 'context_window': 7, 'min_count': 5, 'epochs': 13, 'dim': 356, 'padding': 'post', 'learning_rate': 0.003810440671725004, 'dropout': 0.6130348045537208, 'filter': 21, 'kernel': 3, 'regularizer': 0.006415257528948268}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 21:35:10,755]\u001b[0m Trial 69 finished with values: [0.6779999911785126, 0.7522558853030205, 0.6311708535112748, 0.7405350208282471] and parameters: {'vector_size': 42, 'context_window': 10, 'min_count': 5, 'epochs': 11, 'dim': 251, 'padding': 'post', 'learning_rate': 0.03421825895095091, 'dropout': 0.23199359592295365, 'filter': 36, 'kernel': 14, 'regularizer': 0.577635515351027}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 21:46:03,559]\u001b[0m Trial 70 finished with values: [0.8099999904632569, 0.8302741765975952, 0.8087819008565014, 0.7968480229377747] and parameters: {'vector_size': 71, 'context_window': 4, 'min_count': 7, 'epochs': 14, 'dim': 175, 'padding': 'post', 'learning_rate': 0.003459900512645819, 'dropout': 0.14424079161539996, 'filter': 11, 'kernel': 14, 'regularizer': 0.00017772106838793354}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 21:56:07,501]\u001b[0m Trial 71 finished with values: [0.8179999947547912, 0.8244375705718994, 0.8152785719669993, 0.8079004883766174] and parameters: {'vector_size': 35, 'context_window': 6, 'min_count': 6, 'epochs': 8, 'dim': 406, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 21, 'kernel': 14, 'regularizer': 6.261025385887828e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:01:36,914]\u001b[0m Trial 72 finished with values: [0.7899999976158142, 0.7951267838478089, 0.787292630373106, 0.7814400672912598] and parameters: {'vector_size': 32, 'context_window': 12, 'min_count': 10, 'epochs': 6, 'dim': 175, 'padding': 'post', 'learning_rate': 0.006776473819110473, 'dropout': 0.38131761767696193, 'filter': 42, 'kernel': 12, 'regularizer': 1.0810060589448563e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:08:26,690]\u001b[0m Trial 73 finished with values: [0.821999990940094, 0.7878224492073059, 0.8117945686921015, 0.842894458770752] and parameters: {'vector_size': 22, 'context_window': 7, 'min_count': 10, 'epochs': 9, 'dim': 137, 'padding': 'pre', 'learning_rate': 0.016879682233052685, 'dropout': 0.356568213637418, 'filter': 64, 'kernel': 17, 'regularizer': 0.0006865206485370288}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:24:16,609]\u001b[0m Trial 74 finished with values: [0.8419999957084656, 0.8508225083351135, 0.8391508454631378, 0.8310142397880554] and parameters: {'vector_size': 73, 'context_window': 3, 'min_count': 2, 'epochs': 10, 'dim': 312, 'padding': 'pre', 'learning_rate': 0.0017222305392010438, 'dropout': 0.25958863409319116, 'filter': 13, 'kernel': 14, 'regularizer': 0.004277818633924727}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:33:14,640]\u001b[0m Trial 75 finished with values: [0.8300000071525574, 0.8327368974685669, 0.826091038447192, 0.820372462272644] and parameters: {'vector_size': 67, 'context_window': 4, 'min_count': 5, 'epochs': 14, 'dim': 154, 'padding': 'pre', 'learning_rate': 0.0017222305392010438, 'dropout': 0.674718047954647, 'filter': 6, 'kernel': 4, 'regularizer': 0.00011884604485298875}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:37:04,868]\u001b[0m Trial 76 finished with values: [0.8279999971389771, 0.8272012591361999, 0.8247113568308517, 0.826324737071991] and parameters: {'vector_size': 43, 'context_window': 2, 'min_count': 7, 'epochs': 6, 'dim': 162, 'padding': 'pre', 'learning_rate': 0.004998746010380239, 'dropout': 0.5575100826813773, 'filter': 29, 'kernel': 2, 'regularizer': 1.2289609094604781e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:43:45,065]\u001b[0m Trial 77 finished with values: [0.7860000014305115, 0.7917556643486023, 0.7808125547116278, 0.7714200735092163] and parameters: {'vector_size': 48, 'context_window': 4, 'min_count': 9, 'epochs': 12, 'dim': 309, 'padding': 'post', 'learning_rate': 0.0008348939537165743, 'dropout': 0.11686721219091484, 'filter': 6, 'kernel': 4, 'regularizer': 0.00011884604485298875}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:49:35,298]\u001b[0m Trial 78 finished with values: [0.8439999938011169, 0.8847289204597473, 0.846568709300384, 0.815137755870819] and parameters: {'vector_size': 30, 'context_window': 9, 'min_count': 5, 'epochs': 7, 'dim': 140, 'padding': 'pre', 'learning_rate': 0.0017222305392010438, 'dropout': 0.6565355100393362, 'filter': 49, 'kernel': 14, 'regularizer': 0.001007140599328687}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 22:57:07,301]\u001b[0m Trial 79 finished with values: [0.8319999933242798, 0.8051164746284485, 0.8219685250919989, 0.8472618937492371] and parameters: {'vector_size': 30, 'context_window': 12, 'min_count': 7, 'epochs': 14, 'dim': 162, 'padding': 'pre', 'learning_rate': 0.004998746010380239, 'dropout': 0.38131761767696193, 'filter': 42, 'kernel': 4, 'regularizer': 0.4507184133764991}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 23:00:44,904]\u001b[0m Trial 80 finished with values: [0.793999993801117, 0.8007393717765808, 0.7891864395830874, 0.7800057053565979] and parameters: {'vector_size': 32, 'context_window': 12, 'min_count': 10, 'epochs': 6, 'dim': 67, 'padding': 'pre', 'learning_rate': 0.0047940155614857585, 'dropout': 0.38131761767696193, 'filter': 32, 'kernel': 10, 'regularizer': 0.0007934634314305388}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 23:05:53,856]\u001b[0m Trial 81 finished with values: [0.7259999990463257, 0.7062062859535218, 0.7106519499530253, 0.7166669249534607] and parameters: {'vector_size': 35, 'context_window': 10, 'min_count': 2, 'epochs': 10, 'dim': 41, 'padding': 'post', 'learning_rate': 0.0019582143148307194, 'dropout': 0.2693847678313147, 'filter': 21, 'kernel': 3, 'regularizer': 6.261025385887828e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 23:12:27,463]\u001b[0m Trial 82 finished with values: [0.7759999990463257, 0.8038768768310547, 0.7769244855346755, 0.7544011950492859] and parameters: {'vector_size': 24, 'context_window': 6, 'min_count': 6, 'epochs': 6, 'dim': 406, 'padding': 'pre', 'learning_rate': 0.01583153854952543, 'dropout': 0.38131761767696193, 'filter': 64, 'kernel': 3, 'regularizer': 0.0007934634314305388}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 23:22:32,138]\u001b[0m Trial 83 finished with values: [0.8160000085830689, 0.8347419857978821, 0.8157960112534312, 0.8019252777099609] and parameters: {'vector_size': 97, 'context_window': 4, 'min_count': 5, 'epochs': 6, 'dim': 154, 'padding': 'post', 'learning_rate': 0.0017222305392010438, 'dropout': 0.2425025378135165, 'filter': 49, 'kernel': 14, 'regularizer': 2.7625916423177548e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 23:33:07,354]\u001b[0m Trial 84 finished with values: [0.8300000071525574, 0.840985369682312, 0.8258975600843673, 0.8116947412490845] and parameters: {'vector_size': 90, 'context_window': 10, 'min_count': 3, 'epochs': 6, 'dim': 225, 'padding': 'pre', 'learning_rate': 0.000944635755123106, 'dropout': 0.36577222193378545, 'filter': 14, 'kernel': 13, 'regularizer': 4.322864453287175e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 23:46:01,612]\u001b[0m Trial 85 finished with values: [0.8479999780654908, 0.8387562751770019, 0.8401294188479543, 0.8447138786315918] and parameters: {'vector_size': 90, 'context_window': 10, 'min_count': 2, 'epochs': 12, 'dim': 312, 'padding': 'pre', 'learning_rate': 0.000944635755123106, 'dropout': 0.2693847678313147, 'filter': 13, 'kernel': 9, 'regularizer': 0.004277818633924727}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-08 23:52:44,535]\u001b[0m Trial 86 finished with values: [0.8099999904632569, 0.8632996797561645, 0.815038746457161, 0.7729061961174011] and parameters: {'vector_size': 24, 'context_window': 12, 'min_count': 6, 'epochs': 11, 'dim': 428, 'padding': 'post', 'learning_rate': 0.07588415889006056, 'dropout': 0.5856506609694209, 'filter': 30, 'kernel': 3, 'regularizer': 1.6578335859437683e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:00:31,211]\u001b[0m Trial 87 finished with values: [0.7679999947547913, 0.7219817280769348, 0.7468682049952468, 0.7921007871627808] and parameters: {'vector_size': 14, 'context_window': 7, 'min_count': 7, 'epochs': 9, 'dim': 207, 'padding': 'pre', 'learning_rate': 0.04850222404839205, 'dropout': 0.33103862270409157, 'filter': 64, 'kernel': 15, 'regularizer': 0.0006865206485370288}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:06:25,245]\u001b[0m Trial 88 finished with values: [0.6699999868869781, 0.5825603008270264, 0.5597414864121334, 0.6009487867355346] and parameters: {'vector_size': 95, 'context_window': 3, 'min_count': 4, 'epochs': 6, 'dim': 201, 'padding': 'pre', 'learning_rate': 0.0025889938927600165, 'dropout': 0.2689607706537767, 'filter': 64, 'kernel': 1, 'regularizer': 0.32703465772561185}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:11:02,609]\u001b[0m Trial 89 finished with values: [0.799999988079071, 0.8097189545631409, 0.7978431480230581, 0.7901483178138733] and parameters: {'vector_size': 28, 'context_window': 8, 'min_count': 1, 'epochs': 7, 'dim': 52, 'padding': 'pre', 'learning_rate': 0.0007381370275233295, 'dropout': 0.1658310735775031, 'filter': 63, 'kernel': 10, 'regularizer': 0.08396921872796524}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:19:09,066]\u001b[0m Trial 90 finished with values: [0.799999988079071, 0.8126104593276977, 0.7944423874753437, 0.7808452844619751] and parameters: {'vector_size': 35, 'context_window': 10, 'min_count': 10, 'epochs': 13, 'dim': 356, 'padding': 'post', 'learning_rate': 0.04850222404839205, 'dropout': 0.35631969545026576, 'filter': 21, 'kernel': 3, 'regularizer': 0.0006865206485370288}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:28:20,889]\u001b[0m Trial 91 finished with values: [0.7620000004768371, 0.7566659808158874, 0.7558972718114491, 0.757169759273529] and parameters: {'vector_size': 61, 'context_window': 9, 'min_count': 3, 'epochs': 7, 'dim': 312, 'padding': 'post', 'learning_rate': 0.0001392956031990316, 'dropout': 0.2693847678313147, 'filter': 13, 'kernel': 9, 'regularizer': 4.322864453287175e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:37:32,715]\u001b[0m Trial 92 finished with values: [0.8120000004768372, 0.8305545210838318, 0.8105164459873853, 0.7937539458274842] and parameters: {'vector_size': 43, 'context_window': 10, 'min_count': 10, 'epochs': 12, 'dim': 362, 'padding': 'post', 'learning_rate': 0.0003033941425599605, 'dropout': 0.5575100826813773, 'filter': 29, 'kernel': 5, 'regularizer': 3.3631376654624655e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:45:47,839]\u001b[0m Trial 93 finished with values: [0.8540000081062317, 0.8674321413040161, 0.8531592073344673, 0.8408426523208619] and parameters: {'vector_size': 28, 'context_window': 3, 'min_count': 3, 'epochs': 6, 'dim': 409, 'padding': 'post', 'learning_rate': 0.00047014620761051586, 'dropout': 0.657978734491086, 'filter': 24, 'kernel': 12, 'regularizer': 3.1263436154905014e-05}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 00:54:10,386]\u001b[0m Trial 94 finished with values: [0.8759999990463256, 0.8996344447135926, 0.8760854238399738, 0.8562808394432068] and parameters: {'vector_size': 57, 'context_window': 10, 'min_count': 7, 'epochs': 6, 'dim': 225, 'padding': 'post', 'learning_rate': 0.0004312947164406039, 'dropout': 0.36577222193378545, 'filter': 13, 'kernel': 10, 'regularizer': 0.08165609142696244}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 01:03:32,106]\u001b[0m Trial 95 finished with values: [0.7440000057220459, 0.8167017102241516, 0.7566687647209032, 0.719339120388031] and parameters: {'vector_size': 89, 'context_window': 10, 'min_count': 4, 'epochs': 14, 'dim': 342, 'padding': 'post', 'learning_rate': 0.015506265995074372, 'dropout': 0.2577446490172732, 'filter': 1, 'kernel': 14, 'regularizer': 0.09006028534412477}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 01:17:35,776]\u001b[0m Trial 96 finished with values: [0.8460000038146973, 0.8827568173408509, 0.8466553346280113, 0.8148535490036011] and parameters: {'vector_size': 48, 'context_window': 10, 'min_count': 4, 'epochs': 9, 'dim': 358, 'padding': 'pre', 'learning_rate': 0.0017222305392010438, 'dropout': 0.6535637196987211, 'filter': 30, 'kernel': 14, 'regularizer': 0.015112953378004324}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 01:26:00,095]\u001b[0m Trial 97 finished with values: [0.8460000038146973, 0.8520882248878479, 0.844233647307087, 0.8412249684333801] and parameters: {'vector_size': 14, 'context_window': 8, 'min_count': 4, 'epochs': 11, 'dim': 358, 'padding': 'pre', 'learning_rate': 0.0007381370275233295, 'dropout': 0.4031314888394324, 'filter': 30, 'kernel': 12, 'regularizer': 0.015112953378004324}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 01:31:34,732]\u001b[0m Trial 98 finished with values: [0.8439999938011169, 0.8171552300453186, 0.8343664793852763, 0.8622874617576599] and parameters: {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.49787873612648437}. \u001b[0m\n",
      "\u001b[32m[I 2023-09-09 01:43:47,266]\u001b[0m Trial 99 finished with values: [0.8240000009536743, 0.8376073598861694, 0.8209306279240354, 0.8070683956146241] and parameters: {'vector_size': 90, 'context_window': 12, 'min_count': 7, 'epochs': 6, 'dim': 358, 'padding': 'pre', 'learning_rate': 0.0047940155614857585, 'dropout': 0.19291913673942096, 'filter': 42, 'kernel': 8, 'regularizer': 2.3799437817752373e-05}. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def initiate_embedding(vector_size, window, min_count, epochs, larger_corpus=larger_corpus):\n",
    "    # Train a Word2Vec model on the larger corpus\n",
    "    w2v_model = Word2Vec(larger_corpus, vector_size=vector_size, window=window, min_count=min_count, workers=4, epochs=epochs)\n",
    "    \n",
    "    # out of vocabulary token\n",
    "    OOV_token = 'OOV'\n",
    "\n",
    "    zero_vector = np.zeros(vector_size)\n",
    "    index = len(w2v_model.wv.key_to_index)\n",
    "    w2v_model.wv.key_to_index[OOV_token] = index\n",
    "    index_to_key = list(w2v_model.wv.index_to_key) + [OOV_token]\n",
    "    w2v_model.wv.index_to_key = index_to_key\n",
    "    w2v_model.wv.vectors = np.concatenate((w2v_model.wv.vectors, [zero_vector]), axis=0)\n",
    "\n",
    "    # Extract the embedding weights from the trained model\n",
    "    embedding_weights = w2v_model.wv.vectors\n",
    "    \n",
    "    return w2v_model, embedding_weights\n",
    "\n",
    "def features(training_data, model, dim, padding):\n",
    "    # Step 1: Create a mapping between words in the test set and the corresponding word embeddings\n",
    "    word2idx = {word: i for i, word in enumerate(model.wv.index_to_key)}\n",
    "\n",
    "    training_data['keys'] = training_data['abstract_tokenized'].apply(text_to_vector, word2idx=word2idx, w2v_model=model)\n",
    "    padded = pad_sequences(training_data['keys'], dim, padding=padding, truncating=padding)\n",
    "    \n",
    "    X = padded\n",
    "    y = training_data['label'].values\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "def create_embedding_model(trial, dim, embedding_weights):\n",
    "\n",
    "    # model parameters\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.7)\n",
    "    #threshold = trial.suggest_float('threshold', 0.1, 0.8)\n",
    "    threshold=0.5\n",
    "\n",
    "    filters = trial.suggest_int('filter', 1, 64)\n",
    "    kernel_size = trial.suggest_int('kernel', 1, 20)\n",
    "    #final_dense = trial.suggest_int('units', 10,30)\n",
    "\n",
    "    k_reg = trial.suggest_float('regularizer', 1e-5, 1e-0, log=True)\n",
    "    \n",
    "    #embedding_weights = initiate_embedding()\n",
    "\n",
    "    \n",
    "    model_emb = keras.Sequential([keras.layers.Embedding(input_dim=embedding_weights.shape[0],\n",
    "                                                     output_dim=embedding_weights.shape[1],\n",
    "                                                     input_length = dim,\n",
    "                                                     weights=[embedding_weights], trainable=False),\n",
    "                                  keras.layers.Conv1D(filters=filters,\n",
    "                                                      kernel_size=kernel_size, \n",
    "                                                      activation='relu',\n",
    "                                                      kernel_regularizer=regularizers.L1(k_reg)),\n",
    "\n",
    "                                  keras.layers.MaxPooling1D(pool_size=2),\n",
    "                                  keras.layers.Flatten(),\n",
    "                                  #keras.layers.Dense(final_dense, activation='relu'),\n",
    "\n",
    "                                  #keras.layers.GlobalAveragePooling1D(),\n",
    "                                  keras.layers.Dropout(dropout),\n",
    "\n",
    "                                  keras.layers.Dense(1, activation='sigmoid')\n",
    "                                ])\n",
    "        \n",
    "    \n",
    "    model_emb.compile(optimizer = keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['AUC', keras.metrics.BinaryAccuracy(threshold=threshold),\n",
    "                                 keras.metrics.Recall(thresholds=threshold),\n",
    "                                 keras.metrics.Precision(thresholds=threshold)])\n",
    "    \n",
    "    return model_emb\n",
    "    \n",
    "    \n",
    "def objective(trial):\n",
    "    \n",
    "    # embedding model\n",
    "    vector_size = trial.suggest_int('vector_size', 10, 100)\n",
    "    window = trial.suggest_int('context_window', 2, 12)\n",
    "    min_count = trial.suggest_int('min_count', 1, 10)\n",
    "    epochs = trial.suggest_int('epochs', 6, 14)\n",
    "    \n",
    "    sample_dim = trial.suggest_int('dim', 35, 440)\n",
    "    padding = trial.suggest_categorical('padding', ['pre', 'post'])\n",
    "\n",
    "    loss_list = []; auc_list = []; rec_list = []; acc_list = []; prec_list=[]; f1_list=[]\n",
    "    \n",
    "    for train, val in five_fold:\n",
    "\n",
    "        model, embedding_weights = initiate_embedding(vector_size, window, min_count, epochs)\n",
    "        \n",
    "        X_train, y_train = features(train, model, sample_dim, padding)\n",
    "        X_test, y_test = features(val, model, sample_dim, padding)\n",
    "        \n",
    "        emb_model = create_embedding_model(trial, sample_dim, embedding_weights)\n",
    "\n",
    "        emb_model.fit(X_train, y_train, validation_split=0.25, verbose=0, epochs=100, batch_size=100)\n",
    "    \n",
    "        score = emb_model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        loss_list.append(score[0])\n",
    "        auc_list.append(score[1])\n",
    "        \n",
    "        acc_list.append(score[2])\n",
    "        rec_list.append(score[3])\n",
    "        prec_list.append(score[4])\n",
    "\n",
    "\n",
    "        y_pred = emb_model.predict(X_test, verbose=0)\n",
    "\n",
    "        f1_list.append(calculate_f1_score(y_test, y_pred, threshold=.5, pos_label=1))\n",
    "\n",
    "    return  np.array(acc_list).mean(), np.array(rec_list).mean(), np.array(f1_list).mean(), np.array(prec_list).mean()\n",
    "\n",
    "    #return np.array(loss_list).mean(), np.array(acc_list).mean(), np.array(auc_list).mean(), np.array(mcc_list).mean()\n",
    "\n",
    "\n",
    "study_cnn = optuna.create_study(study_name='embedding_cnn', \n",
    "                            directions=['maximize', 'maximize', 'maximize', 'maximize'], \n",
    "                            sampler=optuna.samplers.NSGAIISampler())\n",
    "\n",
    "study_cnn.optimize(objective, n_trials=100, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model#:  39\n",
      "performance:  [0.8240000009536743, 0.8557191014289856, 0.8245682557206406, 0.7993919610977173]\n",
      "parameter_set:  {'vector_size': 54, 'context_window': 9, 'min_count': 9, 'epochs': 12, 'dim': 220, 'padding': 'pre', 'learning_rate': 0.005025068172771905, 'dropout': 0.17097448392525408, 'filter': 53, 'kernel': 12}\n",
      "model#:  41\n",
      "performance:  [0.8379999876022339, 0.8529966354370118, 0.836459109949163, 0.8237209916114807]\n",
      "parameter_set:  {'vector_size': 36, 'context_window': 9, 'min_count': 6, 'epochs': 14, 'dim': 296, 'padding': 'pre', 'learning_rate': 0.002957173541305207, 'dropout': 0.6813952823962288, 'filter': 33, 'kernel': 19}\n",
      "model#:  43\n",
      "performance:  [0.8359999895095825, 0.8327533960342407, 0.8321374828821467, 0.8326308608055115]\n",
      "parameter_set:  {'vector_size': 68, 'context_window': 3, 'min_count': 3, 'epochs': 9, 'dim': 437, 'padding': 'pre', 'learning_rate': 0.000149405671204404, 'dropout': 0.41186943857120706, 'filter': 44, 'kernel': 17}\n",
      "model#:  76\n",
      "performance:  [0.8400000095367431, 0.8546375393867492, 0.8361942613201994, 0.8205679774284362]\n",
      "parameter_set:  {'vector_size': 89, 'context_window': 12, 'min_count': 7, 'epochs': 11, 'dim': 171, 'padding': 'post', 'learning_rate': 0.005360923185921927, 'dropout': 0.6813952823962288, 'filter': 33, 'kernel': 1}\n"
     ]
    }
   ],
   "source": [
    "# results over 500 tries\n",
    "for i in study_cnn.best_trials:\n",
    "    print('model#: ', i.number)\n",
    "    print('performance: ', i.values)\n",
    "    print('parameter_set: ', i.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/hyperparameter_search/embedding_conv1D/embedding_conv1D.pkl']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = study_cnn.trials_dataframe()\n",
    "cnn_df = pure_df.rename(columns=({'values_0': 'accuracy', 'values_1': 'recall', 'values_2': 'f1', 'values_3': 'precison'}))\n",
    "cnn_df.to_json('data/hyperparameter_search/embedding_conv1D/embedding_conv1D.json')\n",
    "\n",
    "joblib.dump(study_cnn, 'data/hyperparameter_search/embedding_conv1D/embedding_conv1D.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation\n",
    "\n",
    "### 4.0.1 Generate the training/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the unseen test for final testing of the models\n",
    "test = pd.read_json('data/unseen_test.json')\n",
    "\n",
    "if 'doi' in test.columns:\n",
    "    test = test.drop(columns='doi')\n",
    "\n",
    "test['abstract_tokenized'] = test['abstract'].apply(tokenize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Pure embedding evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_embedding(vector_size, window, min_count, epochs, larger_corpus=larger_corpus):\n",
    "    # Train a Word2Vec model on the larger corpus\n",
    "    w2v_model = Word2Vec(larger_corpus, vector_size=vector_size,\n",
    "                         window=window, min_count=min_count,\n",
    "                         workers=4, epochs=epochs)\n",
    "    \n",
    "    # out of vocabulary token\n",
    "    OOV_token = 'OOV'\n",
    "\n",
    "    zero_vector = np.zeros(vector_size)\n",
    "    index = len(w2v_model.wv.key_to_index)\n",
    "    w2v_model.wv.key_to_index[OOV_token] = index\n",
    "    index_to_key = list(w2v_model.wv.index_to_key) + [OOV_token]\n",
    "    w2v_model.wv.index_to_key = index_to_key\n",
    "    w2v_model.wv.vectors = np.concatenate((w2v_model.wv.vectors, [zero_vector]), axis=0)\n",
    "\n",
    "    # Extract the embedding weights from the trained model\n",
    "    embedding_weights = w2v_model.wv.vectors\n",
    "    \n",
    "    return w2v_model, embedding_weights\n",
    "\n",
    "def generate_features(training_data, model, dim, padding):\n",
    "    \n",
    "    word2idx = {word: i for i, word in enumerate(model.wv.index_to_key)}\n",
    "    \n",
    "    \n",
    "    training_data['keys'] = training_data['abstract_tokenized'].apply(text_to_vector, word2idx=word2idx, w2v_model=model)\n",
    "    \n",
    "    padded = pad_sequences(training_data['keys'], dim, padding=padding, truncating=padding)\n",
    "    \n",
    "    X = padded\n",
    "    y = training_data['label'].values\n",
    "\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def get_emb_model(embedding_weights, lr, do, threshold, dim):\n",
    "    \n",
    "    \n",
    "\n",
    "    model = keras.Sequential([keras.layers.Embedding(input_dim=embedding_weights.shape[0],\n",
    "                                                     output_dim=embedding_weights.shape[1],\n",
    "                                                     input_length = dim,\n",
    "                                                     weights=[embedding_weights], trainable=False),\n",
    "                              \n",
    "                              keras.layers.GlobalAveragePooling1D(),\n",
    "                              keras.layers.Dropout(do),\n",
    "                              keras.layers.Dense(1, activation='sigmoid')\n",
    "                             ])\n",
    "        \n",
    "    \n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['AUC',\n",
    "                            keras.metrics.BinaryAccuracy(threshold=threshold),\n",
    "                            keras.metrics.Recall(thresholds=threshold),\n",
    "                            keras.metrics.Precision(thresholds=threshold)])\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "# parametersets\n",
    "# 1. {'vector_size': 95, 'context_window': 9, 'min_count': 4, 'epochs': 8, 'dim': 224, 'padding': 'pre', 'learning_rate': 0.013121832123684417, 'dropout': 0.4402980193837679, 'threshold': 0.5099871650242483}\n",
    "# 2. {'vector_size': 98, 'context_window': 8, 'min_count': 4, 'epochs': 7, 'dim': 217, 'padding': 'pre', 'learning_rate': 0.002104272243300588, 'dropout': 0.5665904244287674, 'threshold': 0.4837522534769876}\n",
    "# ?. {'vector_size': 61, 'context_window': 5, 'min_count': 5, 'epochs': 12, 'dim': 215, 'padding': 'post', 'learning_rate': 0.05715250774676652, 'dropout': 0.3106013643470691, 'threshold': 0.3206284734965039}\n",
    "\n",
    "def test_models(vector_size, context_window, min_count, epochs, dim, padding, learning_rate, dropout, threshold):\n",
    "\n",
    "    #res_dict = {}\n",
    "    temp_dict = {}\n",
    "    train_dict = {}; test_dict = {}\n",
    "\n",
    "    tr_loss_list = []; tr_auc_list = []; tr_prec_list = []; tr_acc_list = []; tr_rec_list = []; tr_fpos_list = []; tr_fneg_list = []\n",
    "    te_loss_list = []; te_auc_list = []; te_prec_list = []; te_acc_list = []; te_rec_list = []; te_fpos_list = []; te_fneg_list = []\n",
    "    \n",
    "\n",
    "    for rs in range(10):\n",
    "\n",
    "        #train_set, test_set = do_shuffle_dataset(rs, df=df)\n",
    "        \n",
    "        #for train, test in zip(train_set, test_set):\n",
    "\n",
    "        model, weights = initiate_embedding(vector_size=vector_size, window=context_window, min_count=min_count, epochs=epochs)\n",
    "\n",
    "        X, y = generate_features(train, model=model, dim=dim, padding=padding)\n",
    "        X_test, y_test = generate_features(test, model=model, dim=dim, padding=padding)\n",
    "\n",
    "        emb_model = get_emb_model(weights, \n",
    "                                lr=learning_rate, \n",
    "                                do=dropout, \n",
    "                                threshold=threshold, \n",
    "                                dim=dim)\n",
    "        \n",
    "        emb_model.fit(X, y, validation_split=0.0, verbose=0, epochs=100, batch_size=100)\n",
    "\n",
    "        tr_score = emb_model.evaluate(X, y, verbose=0)\n",
    "        te_score = emb_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        ################# Manually handle the f1-score #####################\n",
    "        # train\n",
    "        pred = emb_model.predict(X, verbose=0) # y is true\n",
    "        f1_train_pos = calculate_f1_score(y, pred, threshold=threshold, pos_label=1)\n",
    "        f1_trian_neg = calculate_f1_score(y, pred, threshold=threshold, pos_label=0)\n",
    "\n",
    "        # test\n",
    "        test_pred = emb_model.predict(X_test, verbose=0)\n",
    "        f1_test_pos = calculate_f1_score(y_test, test_pred, threshold=threshold, pos_label=1)\n",
    "        f1_test_neg = calculate_f1_score(y_test, test_pred, threshold=threshold, pos_label=0)\n",
    "        \n",
    "        # save the f1-scores\n",
    "        tr_fpos_list.append(f1_train_pos); tr_fneg_list.append(f1_trian_neg)\n",
    "        te_fpos_list.append(f1_test_pos); te_fneg_list.append(f1_test_neg)\n",
    "\n",
    "        tr_loss_list.append(tr_score[0]); tr_auc_list.append(tr_score[1]); tr_acc_list.append(tr_score[2]); tr_rec_list.append(tr_score[3]); tr_prec_list.append(tr_score[4]); \n",
    "        te_loss_list.append(te_score[0]); te_auc_list.append(te_score[1]); te_acc_list.append(te_score[2]); te_rec_list.append(te_score[3]); te_prec_list.append(te_score[4]); \n",
    "\n",
    "        #for i in te_mcc_list:\n",
    "        #    if np.isnan(i):\n",
    "        #        print(emb_model.predict(X_test).values, y_test.values)\n",
    "        \n",
    "    train_dict['loss'] = tr_loss_list; train_dict['auc'] = tr_auc_list; train_dict['prec'] = tr_prec_list; train_dict['acc'] = tr_acc_list; train_dict['rec'] = tr_rec_list; train_dict['f1pos'] = tr_fpos_list; train_dict['f1neg'] = tr_fneg_list\n",
    "    test_dict['loss'] = te_loss_list; test_dict['auc'] = te_auc_list; test_dict['prec'] = te_prec_list; test_dict['acc'] = te_acc_list; test_dict['rec'] = te_rec_list; test_dict['f1pos'] = te_fpos_list; test_dict['f1neg'] = te_fneg_list\n",
    "\n",
    "\n",
    "    temp_dict['train'] = train_dict\n",
    "    temp_dict['test'] = test_dict\n",
    "\n",
    "    #res_dict[str(rs)] = temp_dict\n",
    "        \n",
    "    return temp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vector_size': 77, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'post', 'learning_rate': 0.03176099025801702, 'dropout': 0.5136744356192664, 'threshold': 0.5848579651306551} ,\n",
      "{'vector_size': 56, 'context_window': 6, 'min_count': 6, 'epochs': 14, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.48168409474586804} ,\n",
      "{'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 248, 'padding': 'pre', 'learning_rate': 0.008076709312390297, 'dropout': 0.45592506038880143, 'threshold': 0.5188836233727432} ,\n",
      "{'vector_size': 57, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 248, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.3035608419348366, 'threshold': 0.598413172203673} ,\n",
      "{'vector_size': 89, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.008200999065076656, 'dropout': 0.2368719869678908, 'threshold': 0.49106574275893305} ,\n"
     ]
    }
   ],
   "source": [
    "# filtering, to get the best among the stores \"best_trials\"\n",
    "\n",
    "for i in study_pure.best_trials:\n",
    "    #print(i.params, ',')\n",
    "    if i.values[0] > 0.85:\n",
    "        if i.values[1] > 0.85:\n",
    "            if i.values[2] > 0.85:\n",
    "                if i.values[3] > 0.85:\n",
    "                    #print(i.values)\n",
    "                    print(i.params, ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_para_set {'vector_size': 77, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'post', 'learning_rate': 0.03176099025801702, 'dropout': 0.5136744356192664, 'threshold': 0.5848579651306551}\n",
      "current_para_set {'vector_size': 56, 'context_window': 6, 'min_count': 6, 'epochs': 14, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.48168409474586804}\n",
      "current_para_set {'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 248, 'padding': 'pre', 'learning_rate': 0.008076709312390297, 'dropout': 0.45592506038880143, 'threshold': 0.5188836233727432}\n",
      "current_para_set {'vector_size': 57, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 248, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.3035608419348366, 'threshold': 0.598413172203673}\n",
      "current_para_set {'vector_size': 89, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.008200999065076656, 'dropout': 0.2368719869678908, 'threshold': 0.49106574275893305}\n"
     ]
    }
   ],
   "source": [
    "hyper_list = [{'vector_size': 77, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'post', 'learning_rate': 0.03176099025801702, 'dropout': 0.5136744356192664, 'threshold': 0.5848579651306551} ,\n",
    "{'vector_size': 56, 'context_window': 6, 'min_count': 6, 'epochs': 14, 'dim': 212, 'padding': 'pre', 'learning_rate': 0.0026738550368240127, 'dropout': 0.36981250642348884, 'threshold': 0.48168409474586804} ,\n",
    "{'vector_size': 70, 'context_window': 6, 'min_count': 4, 'epochs': 11, 'dim': 248, 'padding': 'pre', 'learning_rate': 0.008076709312390297, 'dropout': 0.45592506038880143, 'threshold': 0.5188836233727432} ,\n",
    "{'vector_size': 57, 'context_window': 8, 'min_count': 4, 'epochs': 8, 'dim': 248, 'padding': 'post', 'learning_rate': 0.0927796322645081, 'dropout': 0.3035608419348366, 'threshold': 0.598413172203673} ,\n",
    "{'vector_size': 89, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.008200999065076656, 'dropout': 0.2368719869678908, 'threshold': 0.49106574275893305}\n",
    "]\n",
    "\n",
    "single_res = [{'vector_size': 61, 'context_window': 5, 'min_count': 5, 'epochs': 12, 'dim': 215, 'padding': 'post', 'learning_rate': 0.05715250774676652, 'dropout': 0.3106013643470691, 'threshold': 0.3206284734965039},\n",
    "{'vector_size': 67, 'context_window': 6, 'min_count': 4, 'epochs': 10, 'dim': 253, 'padding': 'pre', 'learning_rate': 0.006558954145842335, 'dropout': 0.3398679639334519, 'threshold': 0.1592588728061565}\n",
    "]\n",
    "\n",
    "hyper_dict2 = {}\n",
    "\n",
    "for index, h in enumerate(hyper_list):\n",
    "    print('current_para_set', h)\n",
    "    hyper_dict2['set_' + str(index)] = test_models(vector_size=h['vector_size'],\n",
    "                                                  context_window=h['context_window'],\n",
    "                                                  min_count=h['min_count'],\n",
    "                                                  epochs=h['epochs'],\n",
    "                                                  dim=h['dim'],\n",
    "                                                  padding=h['padding'],\n",
    "                                                  learning_rate=h['learning_rate'],\n",
    "                                                  dropout=h['dropout'],\n",
    "                                                  threshold=h['threshold'])\n",
    "\n",
    "\n",
    "    #print(hyper_dict2['set_' + str(index)])\n",
    "\n",
    "# best\n",
    "# {'vector_size': 89, 'context_window': 7, 'min_count': 5, 'epochs': 6, 'dim': 227, 'padding': 'pre', 'learning_rate': 0.008200999065076656, 'dropout': 0.2368719869678908, 'threshold': 0.49106574275893305}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_0\n",
      "train loss 0.3056305289268494 0.002268255131893136\n",
      "train auc 0.9475037932395936 0.0006035596194860917\n",
      "train prec 0.9055914998054504 0.00513317209897527\n",
      "train acc 0.8804000020027161 0.0021249822319193094\n",
      "train rec 0.8444898009300232 0.006452192446274809\n",
      "train f1pos 0.8736755081110615 0.002460209711773957\n",
      "train f1neg 0.8863811053796666 0.0020446684703642093\n",
      "test loss 0.2626379206776619 0.00390934569660372\n",
      "test auc 0.9678071558475494 0.0017197223540512197\n",
      "test prec 0.9340299665927887 0.0029115654135801867\n",
      "test acc 0.9240000069141387 0.004521552525286969\n",
      "test rec 0.9156862795352936 0.008293187440621807\n",
      "test f1pos 0.9246028770297844 0.004729714772020905\n",
      "test f1neg 0.9233618877193841 0.004311437332183459\n",
      "set_1\n",
      "train loss 0.33589772284030917 0.0014247033649381175\n",
      "train auc 0.9395566046237945 0.000536658546469268\n",
      "train prec 0.8666624665260315 0.0024020510253922787\n",
      "train acc 0.8782000064849853 0.0014742248236828857\n",
      "train rec 0.8881632506847381 0.0022928337757458475\n",
      "train f1pos 0.8772453376074469 0.0014345802769709533\n",
      "train f1neg 0.8791296044248579 0.0015596369870662459\n",
      "test loss 0.30566917955875395 0.003678126895411105\n",
      "test auc 0.9676470756530762 0.0013093118251196532\n",
      "test prec 0.9227171182632447 0.005229781987306749\n",
      "test acc 0.9260000109672546 0.004521549009994238\n",
      "test rec 0.9333333373069763 0.006665384587800703\n",
      "test f1pos 0.9278386567546368 0.00446986201992499\n",
      "test f1neg 0.924033513962977 0.004611283776247986\n",
      "set_2\n",
      "train loss 0.3250047773122787 0.0017613390524553049\n",
      "train auc 0.9423913419246673 0.00045645965113718593\n",
      "train prec 0.875977200269699 0.004101167431769438\n",
      "train acc 0.886000007390976 0.0018135308852863417\n",
      "train rec 0.8942857027053833 0.0037729040355015744\n",
      "train f1pos 0.8849062318754205 0.0016837902039730879\n",
      "train f1neg 0.8870382629726239 0.0020496795113392756\n",
      "test loss 0.28695084154605865 0.004514702567785902\n",
      "test auc 0.9688875615596771 0.0015536178518443257\n",
      "test prec 0.9234099566936493 0.0017894485778869938\n",
      "test acc 0.9210000097751617 0.0034801028471182862\n",
      "test rec 0.9215686321258545 0.007159771566775917\n",
      "test f1pos 0.9223550961123438 0.0036890981719857863\n",
      "test f1neg 0.9195730399938796 0.003260663881851677\n",
      "set_3\n",
      "train loss 0.3167036235332489 0.0085475489308181\n",
      "train auc 0.9470348060131073 0.0008298722826123396\n",
      "train prec 0.9027932703495025 0.014153683079257575\n",
      "train acc 0.8649999976158143 0.007472912846370049\n",
      "train rec 0.8187755048274994 0.02793724730263961\n",
      "train f1pos 0.8541738379949197 0.01086956053114198\n",
      "train f1neg 0.8731739600891574 0.005945125585855668\n",
      "test loss 0.25295458883047106 0.009607328625710343\n",
      "test auc 0.971468597650528 0.0013332583325913535\n",
      "test prec 0.939374428987503 0.008519654937935495\n",
      "test acc 0.8949999988079071 0.016616590540070253\n",
      "test rec 0.8509804010391235 0.03711129077251323\n",
      "test f1pos 0.8882747571166165 0.02038919414305017\n",
      "test f1neg 0.9000341038346468 0.01371331574048757\n",
      "set_4\n",
      "train loss 0.2872030198574066 0.0018338162662374184\n",
      "train auc 0.9518263518810273 0.0005184910506060562\n",
      "train prec 0.8784340620040894 0.002574344698266769\n",
      "train acc 0.8856000006198883 0.0015434435857542847\n",
      "train rec 0.8897959172725678 0.003495304046131035\n",
      "train f1pos 0.884009936464446 0.001630229533261404\n",
      "train f1neg 0.8871295351967723 0.0015351072980979343\n",
      "test loss 0.24151834696531296 0.0018300614758449722\n",
      "test auc 0.9769307732582092 0.0008330258358428336\n",
      "test prec 0.9437665581703186 0.004261748592149179\n",
      "test acc 0.9459999918937683 0.0026666641235351556\n",
      "test rec 0.9509803950786591 0.0032679736614227295\n",
      "test f1pos 0.9472842813209846 0.002553618790832455\n",
      "test f1neg 0.9446420469156109 0.0027977384965128097\n"
     ]
    }
   ],
   "source": [
    "for key, value in hyper_dict2.items():\n",
    "    print(key)\n",
    "    for key2, value2 in value.items():\n",
    "\n",
    "        for metric, li in value2.items():\n",
    "            if key2 == 'train':\n",
    "                print('train', metric, np.array(li).mean(), sem(np.array(li)))\n",
    "            if key2 == 'test':\n",
    "                print('test', metric, np.array(li).mean(), sem(np.array(li)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. CNN embedding testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_embedding(vector_size, window, min_count, epochs, larger_corpus=larger_corpus):\n",
    "    # Train a Word2Vec model on the larger corpus\n",
    "    w2v_model = Word2Vec(larger_corpus, vector_size=vector_size,\n",
    "                         window=window, min_count=min_count,\n",
    "                         workers=4, epochs=epochs)\n",
    "    \n",
    "    # out of vocabulary token\n",
    "    OOV_token = 'OOV'\n",
    "\n",
    "    zero_vector = np.zeros(vector_size)\n",
    "    index = len(w2v_model.wv.key_to_index)\n",
    "    w2v_model.wv.key_to_index[OOV_token] = index\n",
    "    index_to_key = list(w2v_model.wv.index_to_key) + [OOV_token]\n",
    "    w2v_model.wv.index_to_key = index_to_key\n",
    "    w2v_model.wv.vectors = np.concatenate((w2v_model.wv.vectors, [zero_vector]), axis=0)\n",
    "\n",
    "    # Extract the embedding weights from the trained model\n",
    "    embedding_weights = w2v_model.wv.vectors\n",
    "    \n",
    "    return w2v_model, embedding_weights\n",
    "\n",
    "def generate_features(training_data, model, dim, padding):\n",
    "    \n",
    "    word2idx = {word: i for i, word in enumerate(model.wv.index_to_key)}\n",
    "    \n",
    "    training_data['keys'] = training_data['abstract_tokenized'].apply(text_to_vector, word2idx=word2idx, w2v_model=model)\n",
    "    \n",
    "    padded = pad_sequences(training_data['keys'], dim, padding=padding, truncating=padding)\n",
    "    \n",
    "    X = padded\n",
    "    y = training_data['label'].values\n",
    "\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def get_eCNN_model(embedding_weights, lr, do, threshold, dim, filter, kernel_size, units, regularizer):\n",
    "    \n",
    "    \n",
    "\n",
    "    model_eCNN = keras.Sequential([keras.layers.Embedding(input_dim=embedding_weights.shape[0],\n",
    "                                                     output_dim=embedding_weights.shape[1],\n",
    "                                                     input_length = dim,\n",
    "                                                     weights=[embedding_weights], trainable=False),\n",
    "                                  keras.layers.Conv1D(filters=filter,\n",
    "                                                      kernel_size=kernel_size, \n",
    "                                                      activation='relu',\n",
    "                                                      kernel_regularizer=regularizers.L1(regularizer)),\n",
    "\n",
    "                                  keras.layers.MaxPooling1D(pool_size=2),\n",
    "                                  keras.layers.Flatten(),\n",
    "                                  #keras.layers.Dense(units, activation='relu'),\n",
    "\n",
    "                                  #keras.layers.GlobalAveragePooling1D(),\n",
    "                                  keras.layers.Dropout(do),\n",
    "\n",
    "                                  keras.layers.Dense(1, activation='sigmoid')\n",
    "                                ])\n",
    "        \n",
    "    \n",
    "    model_eCNN.compile(optimizer = keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['AUC',\n",
    "                            keras.metrics.BinaryAccuracy(threshold=threshold),\n",
    "                            keras.metrics.Recall(thresholds=threshold),\n",
    "                            keras.metrics.Precision(thresholds=threshold)])\n",
    "\n",
    "    return model_eCNN\n",
    "\n",
    "# parametersets\n",
    "# 1. {'vector_size': 95, 'context_window': 9, 'min_count': 4, 'epochs': 8, 'dim': 224, 'padding': 'pre', 'learning_rate': 0.013121832123684417, 'dropout': 0.4402980193837679, 'threshold': 0.5099871650242483}\n",
    "# 2. {'vector_size': 98, 'context_window': 8, 'min_count': 4, 'epochs': 7, 'dim': 217, 'padding': 'pre', 'learning_rate': 0.002104272243300588, 'dropout': 0.5665904244287674, 'threshold': 0.4837522534769876}\n",
    "\n",
    "\n",
    "def test_eCNN_model(vector_size, context_window, min_count, epochs, dim, padding, learning_rate, dropout, threshold, filter, kernel_size, units, regularizer):\n",
    "    \n",
    "    res_dict = {}\n",
    "    temp_dict = {}\n",
    "    tr_loss_list = []; tr_auc_list = []; tr_prec_list = []; tr_acc_list = []; tr_rec_list = []; tr_fpos_list = []; tr_fneg_list = []\n",
    "    te_loss_list = []; te_auc_list = []; te_prec_list = []; te_acc_list = []; te_rec_list = []; te_fpos_list = []; te_fneg_list = []\n",
    "        \n",
    "    #train_set, test_set = do_shuffle_dataset(rs, df=df)\n",
    "\n",
    "    train_dict = {}; test_dict = {}\n",
    "\n",
    "\n",
    "    for rs in range(10):\n",
    "        \n",
    "        model, weights = initiate_embedding(vector_size=vector_size, window=context_window, min_count=min_count, epochs=epochs)\n",
    "\n",
    "        X, y = generate_features(train, model=model, dim=dim, padding=padding)\n",
    "        X_test, y_test = generate_features(test, model=model, dim=dim, padding=padding)\n",
    "\n",
    "        eCNN_model = get_eCNN_model(weights, \n",
    "                                lr=learning_rate, \n",
    "                                do=dropout, \n",
    "                                threshold=threshold, \n",
    "                                dim=dim,\n",
    "                                filter=filter, \n",
    "                                kernel_size=kernel_size,\n",
    "                                units=units,\n",
    "                                regularizer=regularizer)\n",
    "        \n",
    "        eCNN_model.fit(X, y, validation_split=0.0, verbose=0, epochs=100, batch_size=100)\n",
    "\n",
    "        tr_score = eCNN_model.evaluate(X, y, verbose=0)\n",
    "        te_score = eCNN_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        ################# Manually handle the f1-score #####################\n",
    "        # train\n",
    "        pred = eCNN_model.predict(X, verbose=0) # y is true\n",
    "        f1_train_pos = calculate_f1_score(y, pred, threshold=threshold, pos_label=1)\n",
    "        f1_trian_neg = calculate_f1_score(y, pred, threshold=threshold, pos_label=0)\n",
    "\n",
    "        # test\n",
    "        test_pred = eCNN_model.predict(X_test, verbose=0)\n",
    "        f1_test_pos = calculate_f1_score(y_test, test_pred, threshold=threshold, pos_label=1)\n",
    "        f1_test_neg = calculate_f1_score(y_test, test_pred, threshold=threshold, pos_label=0)\n",
    "        \n",
    "        # save the f1-scores\n",
    "        tr_fpos_list.append(f1_train_pos); tr_fneg_list.append(f1_trian_neg)\n",
    "        te_fpos_list.append(f1_test_pos); te_fneg_list.append(f1_test_neg)\n",
    "        \n",
    "        tr_loss_list.append(tr_score[0]); tr_auc_list.append(tr_score[1]); tr_acc_list.append(tr_score[2]); tr_rec_list.append(tr_score[3]); tr_prec_list.append(tr_score[4]); \n",
    "        te_loss_list.append(te_score[0]); te_auc_list.append(te_score[1]); te_acc_list.append(te_score[2]); te_rec_list.append(te_score[3]); te_prec_list.append(te_score[4]); \n",
    "\n",
    "        #for i in te_mcc_list:\n",
    "        #    if np.isnan(i):\n",
    "        #        print(emb_model.predict(X_test).values, y_test.values)\n",
    "        \n",
    "    train_dict['loss'] = tr_loss_list; train_dict['auc'] = tr_auc_list; train_dict['prec'] = tr_prec_list; train_dict['acc'] = tr_acc_list; train_dict['rec'] = tr_rec_list; train_dict['f1pos'] = tr_fpos_list; train_dict['f1neg'] = tr_fneg_list\n",
    "    test_dict['loss'] = te_loss_list; test_dict['auc'] = te_auc_list; test_dict['prec'] = te_prec_list; test_dict['acc'] = te_acc_list; test_dict['rec'] = te_rec_list; test_dict['f1pos'] = te_fpos_list; test_dict['f1neg'] = te_fneg_list\n",
    "\n",
    "\n",
    "    temp_dict['train'] = train_dict\n",
    "    temp_dict['test'] = test_dict\n",
    "\n",
    "\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vector_size': 24, 'context_window': 6, 'min_count': 6, 'epochs': 12, 'dim': 309, 'padding': 'pre', 'learning_rate': 0.002008567149888518, 'dropout': 0.25961725113431555, 'filter': 64, 'kernel': 3, 'regularizer': 0.49787873612648437} ,\n",
      "{'vector_size': 57, 'context_window': 10, 'min_count': 7, 'epochs': 6, 'dim': 225, 'padding': 'post', 'learning_rate': 0.0004312947164406039, 'dropout': 0.36577222193378545, 'filter': 13, 'kernel': 10, 'regularizer': 0.08165609142696244} ,\n",
      "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.49787873612648437} ,\n"
     ]
    }
   ],
   "source": [
    "for i in study_cnn.best_trials:\n",
    "    print(i.params, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_para_set {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold': 0.2}\n",
      "{'train': {'loss': [1.2730263471603394, 1.3182662725448608, 1.2680500745773315, 1.386303424835205, 1.2588427066802979, 1.2660224437713623, 1.352420687675476, 1.2406877279281616, 1.3105542659759521, 1.32267165184021], 'auc': [0.9422088861465454, 0.9443057775497437, 0.945554256439209, 0.9468827247619629, 0.9458503723144531, 0.9393036961555481, 0.9490676522254944, 0.9426730871200562, 0.9430732727050781, 0.9426010847091675], 'prec': [0.7267080545425415, 0.6713880896568298, 0.6539509296417236, 0.6014851331710815, 0.7169230580329895, 0.6911764740943909, 0.6666666865348816, 0.6648044586181641, 0.6487935781478882, 0.6363636255264282], 'acc': [0.8019999861717224, 0.7519999742507935, 0.7360000014305115, 0.6740000247955322, 0.7919999957084656, 0.7699999809265137, 0.75, 0.7459999918937683, 0.7319999933242798, 0.7139999866485596], 'rec': [0.9551020264625549, 0.9673469662666321, 0.9795918464660645, 0.9918367266654968, 0.9510204195976257, 0.9591836929321289, 0.9795918464660645, 0.9714285731315613, 0.9877551198005676, 0.9714285731315613], 'f1pos': [0.8253968253968255, 0.7926421404682275, 0.7843137254901961, 0.7488443759630201, 0.8175438596491228, 0.8034188034188035, 0.793388429752066, 0.7893864013266998, 0.7831715210355987, 0.7689822294022617], 'f1neg': [0.7713625866050808, 0.6915422885572139, 0.6597938144329897, 0.5356125356125356, 0.7581395348837209, 0.7228915662650602, 0.6835443037974683, 0.6801007556675063, 0.6492146596858638, 0.6246719160104987]}, 'test': {'loss': [1.2718092203140259, 1.2815438508987427, 1.25255286693573, 1.3168864250183105, 1.2470409870147705, 1.2217814922332764, 1.321944236755371, 1.2208610773086548, 1.2747248411178589, 1.2676945924758911], 'auc': [0.9575830698013306, 0.9689875841140747, 0.9699880480766296, 0.971788763999939, 0.9615846276283264, 0.9643857479095459, 0.965786337852478, 0.9653862118721008, 0.9661864638328552, 0.9723889827728271], 'prec': [0.746268630027771, 0.7142857313156128, 0.6538461446762085, 0.6219512224197388, 0.7246376872062683, 0.7692307829856873, 0.7142857313156128, 0.6849315166473389, 0.649350643157959, 0.6578947305679321], 'acc': [0.8199999928474426, 0.7900000214576721, 0.7300000190734863, 0.6899999976158142, 0.800000011920929, 0.8399999737739563, 0.7900000214576721, 0.7599999904632568, 0.7200000286102295, 0.7300000190734863], 'rec': [0.9803921580314636, 0.9803921580314636, 1.0, 1.0, 0.9803921580314636, 0.9803921580314636, 0.9803921580314636, 0.9803921580314636, 0.9803921580314636, 0.9803921580314636], 'f1pos': [0.847457627118644, 0.8264462809917354, 0.7906976744186047, 0.7669172932330827, 0.8333333333333334, 0.8620689655172413, 0.8264462809917354, 0.8064516129032259, 0.7812499999999999, 0.7874015748031497], 'f1neg': [0.7804878048780488, 0.7341772151898733, 0.6197183098591549, 0.5373134328358209, 0.75, 0.8095238095238094, 0.7341772151898733, 0.6842105263157895, 0.6111111111111112, 0.6301369863013699]}}\n",
      "current_para_set {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold': 0.3}\n",
      "{'train': {'loss': [1.245693325996399, 1.3654963970184326, 1.2862898111343384, 1.2902830839157104, 1.3139076232910156, 1.2818126678466797, 1.2623118162155151, 1.276615858078003, 1.3306653499603271, 1.2676316499710083], 'auc': [0.9423209428787231, 0.9482512474060059, 0.9501640796661377, 0.9508123397827148, 0.9433693289756775, 0.9431291818618774, 0.9505562782287598, 0.9416726231575012, 0.9500600099563599, 0.9464265704154968], 'prec': [0.8085106611251831, 0.8821138143539429, 0.6685393452644348, 0.7195122241973877, 0.8962655663490295, 0.8345588445663452, 0.7898305058479309, 0.7057057023048401, 0.6790831089019775, 0.7358490824699402], 'acc': [0.8579999804496765, 0.8859999775886536, 0.75, 0.7979999780654907, 0.8920000195503235, 0.8740000128746033, 0.8519999980926514, 0.7839999794960022, 0.7599999904632568, 0.8100000023841858], 'rec': [0.9306122660636902, 0.8857142925262451, 0.9714285731315613, 0.9632652997970581, 0.8816326260566711, 0.9265305995941162, 0.9510204195976257, 0.9591836929321289, 0.9673469662666321, 0.9551020264625549], 'f1pos': [0.8652751423149905, 0.8839103869653767, 0.7920133111480865, 0.8237347294938917, 0.888888888888889, 0.8781431334622825, 0.8629629629629628, 0.8131487889273357, 0.797979797979798, 0.8312611012433393], 'f1neg': [0.8498942917547568, 0.8880157170923378, 0.6867167919799498, 0.7634660421545668, 0.8949416342412453, 0.8695652173913043, 0.8391304347826087, 0.7440758293838863, 0.7044334975369457, 0.7826086956521738]}, 'test': {'loss': [1.2327295541763306, 1.379945993423462, 1.2739626169204712, 1.2490580081939697, 1.3239752054214478, 1.2506380081176758, 1.237038493156433, 1.2497979402542114, 1.312208890914917, 1.2429955005645752], 'auc': [0.9639855623245239, 0.9641857147216797, 0.9597839117050171, 0.9793918132781982, 0.9603841304779053, 0.9671869277954102, 0.9739896655082703, 0.9619848132133484, 0.9635854959487915, 0.9727891087532043], 'prec': [0.8771929740905762, 0.9166666865348816, 0.6756756901741028, 0.7352941036224365, 0.9038461446762085, 0.875, 0.8196721076965332, 0.746268630027771, 0.6849315166473389, 0.7692307829856873], 'acc': [0.9200000166893005, 0.8899999856948853, 0.75, 0.8100000023841858, 0.9100000262260437, 0.9100000262260437, 0.8799999952316284, 0.8199999928474426, 0.7599999904632568, 0.8399999737739563], 'rec': [0.9803921580314636, 0.8627451062202454, 0.9803921580314636, 0.9803921580314636, 0.9215686321258545, 0.9607843160629272, 0.9803921580314636, 0.9803921580314636, 0.9803921580314636, 0.9803921580314636], 'f1pos': [0.9259259259259259, 0.888888888888889, 0.8, 0.8403361344537814, 0.9126213592233009, 0.9158878504672897, 0.8928571428571428, 0.847457627118644, 0.8064516129032259, 0.8620689655172413], 'f1neg': [0.9130434782608695, 0.8910891089108911, 0.6666666666666667, 0.7654320987654322, 0.9072164948453607, 0.9032258064516128, 0.8636363636363635, 0.7804878048780488, 0.6842105263157895, 0.8095238095238094]}}\n",
      "current_para_set {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold': 0.4}\n",
      "{'train': {'loss': [1.2864758968353271, 1.326368808746338, 1.2908530235290527, 1.2359923124313354, 1.256912350654602, 1.2548273801803589, 1.273720622062683, 1.3187508583068848, 1.2237069606781006, 1.297190546989441], 'auc': [0.9424569606781006, 0.9433853626251221, 0.9367586970329285, 0.9455382823944092, 0.9506282806396484, 0.9417446851730347, 0.9476190805435181, 0.9490436315536499, 0.9496278762817383, 0.9502761363983154], 'prec': [0.8685259222984314, 0.8879668116569519, 0.8714859485626221, 0.8407407402992249, 0.8351648449897766, 0.8532818555831909, 0.8571428656578064, 0.7476038336753845, 0.8226950168609619, 0.7952218651771545], 'acc': [0.8799999952316284, 0.8840000033378601, 0.8799999952316284, 0.878000020980835, 0.8759999871253967, 0.8759999871253967, 0.8899999856948853, 0.8199999928474426, 0.8740000128746033, 0.8560000061988831], 'rec': [0.8897958993911743, 0.8734694123268127, 0.8857142925262451, 0.9265305995941162, 0.9306122660636902, 0.9020408391952515, 0.9306122660636902, 0.9551020264625549, 0.9469387531280518, 0.9510204195976257], 'f1pos': [0.8790322580645161, 0.8806584362139918, 0.8785425101214575, 0.8815533980582524, 0.8803088803088803, 0.876984126984127, 0.8923679060665362, 0.8387096774193549, 0.8804554079696394, 0.866171003717472], 'f1neg': [0.880952380952381, 0.88715953307393, 0.8814229249011857, 0.8742268041237113, 0.8713692946058091, 0.8749999999999999, 0.8875255623721882, 0.7963800904977376, 0.8668076109936576, 0.8441558441558441]}, 'test': {'loss': [1.274592638015747, 1.3111562728881836, 1.2753143310546875, 1.2072526216506958, 1.2371258735656738, 1.2397691011428833, 1.2515678405761719, 1.2808853387832642, 1.2046045064926147, 1.2515244483947754], 'auc': [0.9625850319862366, 0.9719887971878052, 0.9623850584030151, 0.9663865566253662, 0.9699880480766296, 0.9631853103637695, 0.9601840972900391, 0.9651861190795898, 0.9683873653411865, 0.9673870205879211], 'prec': [0.9215686321258545, 0.9038461446762085, 0.8867924809455872, 0.8620689511299133, 0.875, 0.875, 0.8909090757369995, 0.8196721076965332, 0.8771929740905762, 0.8474576473236084], 'acc': [0.9200000166893005, 0.9100000262260437, 0.8999999761581421, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9200000166893005, 0.8799999952316284, 0.9200000166893005, 0.8999999761581421], 'rec': [0.9215686321258545, 0.9215686321258545, 0.9215686321258545, 0.9803921580314636, 0.9607843160629272, 0.9607843160629272, 0.9607843160629272, 0.9803921580314636, 0.9803921580314636, 0.9803921580314636], 'f1pos': [0.9215686274509803, 0.9126213592233009, 0.9038461538461539, 0.9174311926605505, 0.9158878504672897, 0.9158878504672897, 0.9245283018867925, 0.8928571428571428, 0.9259259259259259, 0.909090909090909], 'f1neg': [0.9183673469387755, 0.9072164948453607, 0.8958333333333333, 0.9010989010989012, 0.9032258064516128, 0.9032258064516128, 0.9148936170212767, 0.8636363636363635, 0.9130434782608695, 0.888888888888889]}}\n",
      "current_para_set {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold': 0.5}\n",
      "{'train': {'loss': [1.255494236946106, 1.250248670578003, 1.2720798254013062, 1.3099104166030884, 1.286524772644043, 1.275626301765442, 1.2598332166671753, 1.2393217086791992, 1.2509788274765015, 1.2671191692352295], 'auc': [0.9518687129020691, 0.9480991959571838, 0.9477150440216064, 0.9497239589691162, 0.9449139833450317, 0.9472668170928955, 0.9472509026527405, 0.9458423256874084, 0.9459784030914307, 0.9457062482833862], 'prec': [0.9189189076423645, 0.8991596698760986, 0.8804780840873718, 0.8243727684020996, 0.8695651888847351, 0.8671875, 0.9115044474601746, 0.9099099040031433, 0.831501841545105, 0.8943089246749878], 'acc': [0.8820000290870667, 0.8899999856948853, 0.8920000195503235, 0.871999979019165, 0.8840000033378601, 0.8859999775886536, 0.8820000290870667, 0.8740000128746033, 0.871999979019165, 0.8980000019073486], 'rec': [0.8326530456542969, 0.8734694123268127, 0.9020408391952515, 0.9387755393981934, 0.8979591727256775, 0.9061224460601807, 0.8408163189888, 0.8244897723197937, 0.9265305995941162, 0.8979591727256775], 'f1pos': [0.8736616702355461, 0.8861283643892339, 0.8911290322580645, 0.8778625954198473, 0.8835341365461847, 0.8862275449101796, 0.8747346072186836, 0.8650963597430407, 0.8764478764478764, 0.8961303462321792], 'f1neg': [0.8893058161350845, 0.8936170212765957, 0.8928571428571428, 0.865546218487395, 0.8844621513944223, 0.8857715430861723, 0.8884688090737239, 0.8818011257035647, 0.8672199170124482, 0.8998035363457759]}, 'test': {'loss': [1.2412352561950684, 1.2266770601272583, 1.2370212078094482, 1.2779054641723633, 1.2583472728729248, 1.2427802085876465, 1.2257858514785767, 1.2230397462844849, 1.218479871749878, 1.2540512084960938], 'auc': [0.9683873653411865, 0.9665865898132324, 0.9703881740570068, 0.9671869277954102, 0.9633854031562805, 0.9663865566253662, 0.9687875509262085, 0.9631853103637695, 0.9689876437187195, 0.9547819495201111], 'prec': [0.9375, 0.9215686321258545, 0.9074074029922485, 0.8474576473236084, 0.9230769276618958, 0.875, 0.9399999976158142, 0.9347826242446899, 0.875, 0.9038461446762085], 'acc': [0.9100000262260437, 0.9200000166893005, 0.9300000071525574, 0.8999999761581421, 0.9300000071525574, 0.9100000262260437, 0.9300000071525574, 0.8899999856948853, 0.9100000262260437, 0.9100000262260437], 'rec': [0.8823529481887817, 0.9215686321258545, 0.9607843160629272, 0.9803921580314636, 0.9411764740943909, 0.9607843160629272, 0.9215686321258545, 0.843137264251709, 0.9607843160629272, 0.9215686321258545], 'f1pos': [0.9090909090909091, 0.9215686274509803, 0.9333333333333333, 0.909090909090909, 0.9320388349514563, 0.9158878504672897, 0.9306930693069307, 0.8865979381443299, 0.9158878504672897, 0.9126213592233009], 'f1neg': [0.9108910891089108, 0.9183673469387755, 0.9263157894736843, 0.888888888888889, 0.9278350515463918, 0.9032258064516128, 0.9292929292929293, 0.8932038834951458, 0.9032258064516128, 0.9072164948453607]}}\n",
      "current_para_set {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold': 0.6}\n",
      "{'train': {'loss': [1.2772974967956543, 1.2833043336868286, 1.26395583152771, 1.3107497692108154, 1.3141131401062012, 1.3137603998184204, 1.268508791923523, 1.3114734888076782, 1.2486108541488647, 1.2919940948486328], 'auc': [0.9525570273399353, 0.9483953714370728, 0.9442416429519653, 0.9496438503265381, 0.9520047903060913, 0.9468187093734741, 0.9464185237884521, 0.9443536996841431, 0.9421448707580566, 0.9463545680046082], 'prec': [0.9821428656578064, 0.9078947305679321, 0.8705882430076599, 0.8840000033378601, 0.9025423526763916, 0.9082969427108765, 0.9248826503753662, 0.8544061183929443, 0.9134615659713745, 0.9347826242446899], 'acc': [0.8339999914169312, 0.8820000290870667, 0.8880000114440918, 0.8939999938011169, 0.8899999856948853, 0.8840000033378601, 0.871999979019165, 0.8799999952316284, 0.8539999723434448, 0.8299999833106995], 'rec': [0.6734693646430969, 0.844897985458374, 0.9061224460601807, 0.9020408391952515, 0.8693877458572388, 0.8489795923233032, 0.8040816187858582, 0.9102040529251099, 0.7755101919174194, 0.7020407915115356], 'f1pos': [0.7990314769975786, 0.8752642706131079, 0.888, 0.8929292929292929, 0.8856548856548857, 0.8776371308016878, 0.8602620087336245, 0.8814229249011858, 0.8388520971302429, 0.8018648018648019], 'f1neg': [0.858603066439523, 0.8880455407969641, 0.888, 0.8950495049504951, 0.8940269749518305, 0.8897338403041825, 0.8819188191881919, 0.8785425101214575, 0.86654478976234, 0.851138353765324]}, 'test': {'loss': [1.290714979171753, 1.2688624858856201, 1.2191581726074219, 1.2845839262008667, 1.2935250997543335, 1.2923191785812378, 1.2462332248687744, 1.2672237157821655, 1.218738079071045, 1.297268033027649], 'auc': [0.9713885188102722, 0.9581832885742188, 0.965786337852478, 0.9659863710403442, 0.9707883596420288, 0.9681872725486755, 0.9621849060058594, 0.9653862118721008, 0.9703881740570068, 0.9595838189125061], 'prec': [1.0, 0.9387755393981934, 0.8703703880310059, 0.9038461446762085, 0.9200000166893005, 0.957446813583374, 0.9545454382896423, 0.8909090757369995, 0.9534883499145508, 0.9375], 'acc': [0.7599999904632568, 0.9200000166893005, 0.8899999856948853, 0.9100000262260437, 0.9100000262260437, 0.9200000166893005, 0.8899999856948853, 0.9200000166893005, 0.8799999952316284, 0.7699999809265137], 'rec': [0.529411792755127, 0.9019607901573181, 0.9215686321258545, 0.9215686321258545, 0.9019607901573181, 0.8823529481887817, 0.8235294222831726, 0.9607843160629272, 0.8039215803146362, 0.5882353186607361], 'f1pos': [0.6923076923076924, 0.92, 0.8952380952380952, 0.9126213592233009, 0.9108910891089109, 0.9183673469387754, 0.8842105263157896, 0.9245283018867925, 0.8723404255319148, 0.7228915662650602], 'f1neg': [0.8032786885245902, 0.92, 0.8842105263157894, 0.9072164948453607, 0.9090909090909091, 0.9215686274509803, 0.8952380952380952, 0.9148936170212767, 0.8867924528301887, 0.8034188034188035]}}\n",
      "current_para_set {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold': 0.7}\n",
      "{'train': {'loss': [1.3673847913742065, 1.3055111169815063, 1.3162834644317627, 1.2550162076950073, 1.5246573686599731, 1.271896481513977, 1.3351259231567383, 1.2995085716247559, 1.2611316442489624, 1.2487788200378418], 'auc': [0.9465305805206299, 0.9421128034591675, 0.9458903074264526, 0.9495638012886047, 0.9433533549308777, 0.9440656304359436, 0.9521968364715576, 0.9451861381530762, 0.9462344646453857, 0.945770263671875], 'prec': [0.8571428656578064, 0.9575757384300232, 0.9111111164093018, 0.9128440618515015, 1.0, 0.936170220375061, 0.8799999952316284, 0.902953565120697, 0.9378238320350647, 0.9215686321258545], 'acc': [0.8799999952316284, 0.8119999766349792, 0.8799999952316284, 0.8700000047683716, 0.5839999914169312, 0.8379999995231628, 0.8899999856948853, 0.8920000195503235, 0.8479999899864197, 0.8539999723434448], 'rec': [0.9061224460601807, 0.6448979377746582, 0.8367347121238708, 0.8122448921203613, 0.15102040767669678, 0.718367338180542, 0.8979591727256775, 0.8734694123268127, 0.7387754917144775, 0.7673469185829163], 'f1pos': [0.8809523809523809, 0.7707317073170732, 0.8723404255319148, 0.8596112311015118, 0.2624113475177305, 0.812933025404157, 0.888888888888889, 0.8879668049792531, 0.8264840182648401, 0.8374164810690423], 'f1neg': [0.879032258064516, 0.8406779661016949, 0.8867924528301887, 0.8789571694599628, 0.7103064066852368, 0.857142857142857, 0.8910891089108911, 0.8957528957528959, 0.8647686832740213, 0.867513611615245]}, 'test': {'loss': [1.3280091285705566, 1.2973394393920898, 1.2786856889724731, 1.2228072881698608, 1.5821914672851562, 1.2554261684417725, 1.3036733865737915, 1.2647250890731812, 1.25812828540802, 1.2261335849761963], 'auc': [0.9667867422103882, 0.9577831029891968, 0.9665865898132324, 0.97198885679245, 0.9535814523696899, 0.9673869609832764, 0.9689876437187195, 0.9627851247787476, 0.9553821086883545, 0.9687875509262085], 'prec': [0.9056603908538818, 0.9666666388511658, 0.95652174949646, 0.9333333373069763, 1.0, 0.970588207244873, 0.8888888955116272, 0.9399999976158142, 0.9428571462631226, 0.949999988079071], 'acc': [0.9200000166893005, 0.7699999809265137, 0.9100000262260437, 0.8799999952316284, 0.5400000214576721, 0.8100000023841858, 0.9100000262260437, 0.9300000071525574, 0.800000011920929, 0.8500000238418579], 'rec': [0.9411764740943909, 0.5686274766921997, 0.8627451062202454, 0.8235294222831726, 0.09803921729326248, 0.6470588445663452, 0.9411764740943909, 0.9215686321258545, 0.6470588445663452, 0.7450980544090271], 'f1pos': [0.923076923076923, 0.7160493827160493, 0.9072164948453608, 0.8749999999999999, 0.17857142857142855, 0.7764705882352942, 0.9142857142857143, 0.9306930693069307, 0.7674418604651163, 0.8351648351648352], 'f1neg': [0.9166666666666666, 0.8067226890756303, 0.912621359223301, 0.8846153846153846, 0.6805555555555556, 0.8347826086956521, 0.9052631578947369, 0.9292929292929293, 0.8245614035087718, 0.8623853211009175]}}\n",
      "current_para_set {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold': 0.8}\n",
      "{'train': {'loss': [1.3277933597564697, 1.3047131299972534, 1.3453123569488525, 1.2111611366271973, 1.356911063194275, 1.3021036386489868, 1.3374347686767578, 1.2592108249664307, 1.3022443056106567, 1.2897840738296509], 'auc': [0.9417526721954346, 0.9448899030685425, 0.9465385675430298, 0.9444258213043213, 0.941320538520813, 0.9471468925476074, 0.9438896179199219, 0.9501881003379822, 0.9459543824195862, 0.9505642056465149], 'prec': [0.9906542301177979, 0.956250011920929, 0.9219512343406677, 0.9662162065505981, 0.9095022678375244, 0.9890109896659851, 0.9200000166893005, 0.9264705777168274, 0.9685039520263672, 0.9308510422706604], 'acc': [0.7200000286102295, 0.8019999861717224, 0.8560000061988831, 0.7860000133514404, 0.871999979019165, 0.6880000233650208, 0.8880000114440918, 0.8579999804496765, 0.7480000257492065, 0.8339999914169312], 'rec': [0.4326530694961548, 0.6244897842407227, 0.7714285850524902, 0.5836734771728516, 0.8204081654548645, 0.36734694242477417, 0.844897985458374, 0.7714285850524902, 0.5020408034324646, 0.7142857313156128], 'f1pos': [0.6022727272727273, 0.7555555555555556, 0.8400000000000001, 0.7277353689567431, 0.8626609442060086, 0.5357142857142858, 0.8808510638297873, 0.841870824053452, 0.6612903225806452, 0.8083140877598153], 'f1neg': [0.7839506172839507, 0.8336134453781512, 0.869090909090909, 0.8237232289950577, 0.8801498127340824, 0.7650602409638554, 0.8943396226415093, 0.8711433756805809, 0.7993630573248407, 0.8536155202821868]}, 'test': {'loss': [1.3028347492218018, 1.2901371717453003, 1.3051915168762207, 1.1759696006774902, 1.305985450744629, 1.3176449537277222, 1.3021208047866821, 1.215091586112976, 1.2814098596572876, 1.2644014358520508], 'auc': [0.9701880812644958, 0.9633853435516357, 0.965586245059967, 0.9631853103637695, 0.9649860858917236, 0.9599840044975281, 0.9625850915908813, 0.9683873653411865, 0.966586709022522, 0.9717887043952942], 'prec': [1.0, 0.9655172228813171, 0.9545454382896423, 0.9666666388511658, 0.95652174949646, 1.0, 0.9555555582046509, 0.9512194991111755, 1.0, 0.9444444179534912], 'acc': [0.6700000166893005, 0.7599999904632568, 0.8899999856948853, 0.7699999809265137, 0.9100000262260437, 0.6000000238418579, 0.8999999761581421, 0.8600000143051147, 0.7099999785423279, 0.8100000023841858], 'rec': [0.3529411852359772, 0.5490196347236633, 0.8235294222831726, 0.5686274766921997, 0.8627451062202454, 0.21568627655506134, 0.843137264251709, 0.7647058963775635, 0.4313725531101227, 0.6666666865348816], 'f1pos': [0.5217391304347826, 0.7000000000000002, 0.8842105263157896, 0.7160493827160493, 0.9072164948453608, 0.3548387096774193, 0.8958333333333333, 0.8478260869565216, 0.6027397260273972, 0.7816091954022987], 'f1neg': [0.748091603053435, 0.8, 0.8952380952380952, 0.8067226890756303, 0.912621359223301, 0.7101449275362319, 0.9038461538461537, 0.8703703703703702, 0.7716535433070866, 0.831858407079646]}}\n"
     ]
    }
   ],
   "source": [
    "hyper_list = [{'vector_size': 24, 'context_window': 6, 'min_count': 6, 'epochs': 12, 'dim': 309, 'padding': 'pre', 'learning_rate': 0.002008567149888518, 'dropout': 0.25961725113431555, 'filter': 64, 'kernel': 3, 'regularizer': 0.49787873612648437} ,\n",
    "{'vector_size': 57, 'context_window': 10, 'min_count': 7, 'epochs': 6, 'dim': 225, 'padding': 'post', 'learning_rate': 0.0004312947164406039, 'dropout': 0.36577222193378545, 'filter': 13, 'kernel': 10, 'regularizer': 0.08165609142696244} ,\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.49787873612648437},\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.1}]\n",
    "\n",
    "threshold_adjusting = [{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.2},\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.3},\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.4},\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.5},\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.6},\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.7},\n",
    "{'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.8}]\n",
    "\n",
    "eCNN_dict = {}\n",
    "\n",
    "for index, h in enumerate(threshold_adjusting):\n",
    "    print('current_para_set', h)\n",
    "    #h['threshold'] = 0.3\n",
    "    h['units'] = 1\n",
    "    eCNN_dict['set_' + str(index)] = test_eCNN_model(vector_size=h['vector_size'],\n",
    "                                                  context_window=h['context_window'],\n",
    "                                                  min_count=h['min_count'],\n",
    "                                                  epochs=h['epochs'],\n",
    "                                                  dim=h['dim'],\n",
    "                                                  padding=h['padding'],\n",
    "                                                  learning_rate=h['learning_rate'],\n",
    "                                                  dropout=h['dropout'],\n",
    "                                                  threshold=h['threshold'],\n",
    "                                                  filter=h['filter'],\n",
    "                                                  kernel_size=h['kernel'],\n",
    "                                                  units=h['units'],\n",
    "                                                  regularizer=h['regularizer']  \n",
    "                                                  )\n",
    "\n",
    "\n",
    "    print(eCNN_dict['set_' + str(index)])\n",
    "\n",
    "\n",
    "# best performing set\n",
    "# {'vector_size': 24, 'context_window': 10, 'min_count': 6, 'epochs': 11, 'dim': 165, 'padding': 'post', 'learning_rate': 0.00553324031182354, 'dropout': 0.25961725113431555, 'filter': 36, 'kernel': 3, 'regularizer': 0.5, 'threshold':0.5},\n",
    "\n",
    "# is outperformed by a simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv1D(\n",
    "    filters=10,\n",
    "    kernel_size=10, \n",
    "    activation='relu',\n",
    "    kernel_regularizer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_0\n",
      "set_1\n",
      "set_2\n",
      "set_3\n",
      "train loss 1.2667137145996095 0.006505596821005861 0.019516790463017585\n",
      "train auc 0.9474365592002869 0.0006623298162016013 0.001986989448604804\n",
      "train prec 0.880690723657608 0.010375513639304381 0.031126540917913146\n",
      "train acc 0.8832000017166137 0.002768073235353604 0.008304219706060812\n",
      "train rec 0.88408163189888 0.012546551977426358 0.037639655932279074\n",
      "train f1pos 0.8810952533400837 0.002921339637385103 0.00876401891215531\n",
      "train f1neg 0.8848853281372324 0.0034821320948246305 0.010446396284473893\n",
      "test loss 1.2405323147773744 0.0058845249006613904 0.01765357470198417\n",
      "test auc 0.9658063471317291 0.0014289957151290542 0.004286987145387162\n",
      "test prec 0.906563937664032 0.00992378721213859 0.02977136163641577\n",
      "test acc 0.9140000104904175 0.004268751316126819 0.01280625394838046\n",
      "test rec 0.929411768913269 0.013137091532158985 0.039411274596476954\n",
      "test f1pos 0.9166810681526728 0.00443638831381126 0.013309164941433782\n",
      "test f1neg 0.9108463086493312 0.0045307237111461484 0.013592171133438446\n",
      "set_4\n",
      "set_5\n",
      "set_6\n"
     ]
    }
   ],
   "source": [
    "for key, value in eCNN_dict.items():\n",
    "    print(key)\n",
    "    if key == 'set_3':\n",
    "        for key2, value2 in value.items():\n",
    "\n",
    "            for metric, li in value2.items():\n",
    "                if key2 == 'train':\n",
    "                    print('train', metric, np.array(li).mean(), sem(np.array(li)), np.array(li).std())\n",
    "\n",
    "                if key2 == 'test':\n",
    "                    print('test', metric, np.array(li).mean(), sem(np.array(li)), np.array(li).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'loss': [1.255494236946106,\n",
       "   1.250248670578003,\n",
       "   1.2720798254013062,\n",
       "   1.3099104166030884,\n",
       "   1.286524772644043,\n",
       "   1.275626301765442,\n",
       "   1.2598332166671753,\n",
       "   1.2393217086791992,\n",
       "   1.2509788274765015,\n",
       "   1.2671191692352295],\n",
       "  'auc': [0.9518687129020691,\n",
       "   0.9480991959571838,\n",
       "   0.9477150440216064,\n",
       "   0.9497239589691162,\n",
       "   0.9449139833450317,\n",
       "   0.9472668170928955,\n",
       "   0.9472509026527405,\n",
       "   0.9458423256874084,\n",
       "   0.9459784030914307,\n",
       "   0.9457062482833862],\n",
       "  'prec': [0.9189189076423645,\n",
       "   0.8991596698760986,\n",
       "   0.8804780840873718,\n",
       "   0.8243727684020996,\n",
       "   0.8695651888847351,\n",
       "   0.8671875,\n",
       "   0.9115044474601746,\n",
       "   0.9099099040031433,\n",
       "   0.831501841545105,\n",
       "   0.8943089246749878],\n",
       "  'acc': [0.8820000290870667,\n",
       "   0.8899999856948853,\n",
       "   0.8920000195503235,\n",
       "   0.871999979019165,\n",
       "   0.8840000033378601,\n",
       "   0.8859999775886536,\n",
       "   0.8820000290870667,\n",
       "   0.8740000128746033,\n",
       "   0.871999979019165,\n",
       "   0.8980000019073486],\n",
       "  'rec': [0.8326530456542969,\n",
       "   0.8734694123268127,\n",
       "   0.9020408391952515,\n",
       "   0.9387755393981934,\n",
       "   0.8979591727256775,\n",
       "   0.9061224460601807,\n",
       "   0.8408163189888,\n",
       "   0.8244897723197937,\n",
       "   0.9265305995941162,\n",
       "   0.8979591727256775],\n",
       "  'f1pos': [0.8736616702355461,\n",
       "   0.8861283643892339,\n",
       "   0.8911290322580645,\n",
       "   0.8778625954198473,\n",
       "   0.8835341365461847,\n",
       "   0.8862275449101796,\n",
       "   0.8747346072186836,\n",
       "   0.8650963597430407,\n",
       "   0.8764478764478764,\n",
       "   0.8961303462321792],\n",
       "  'f1neg': [0.8893058161350845,\n",
       "   0.8936170212765957,\n",
       "   0.8928571428571428,\n",
       "   0.865546218487395,\n",
       "   0.8844621513944223,\n",
       "   0.8857715430861723,\n",
       "   0.8884688090737239,\n",
       "   0.8818011257035647,\n",
       "   0.8672199170124482,\n",
       "   0.8998035363457759]},\n",
       " 'test': {'loss': [1.2412352561950684,\n",
       "   1.2266770601272583,\n",
       "   1.2370212078094482,\n",
       "   1.2779054641723633,\n",
       "   1.2583472728729248,\n",
       "   1.2427802085876465,\n",
       "   1.2257858514785767,\n",
       "   1.2230397462844849,\n",
       "   1.218479871749878,\n",
       "   1.2540512084960938],\n",
       "  'auc': [0.9683873653411865,\n",
       "   0.9665865898132324,\n",
       "   0.9703881740570068,\n",
       "   0.9671869277954102,\n",
       "   0.9633854031562805,\n",
       "   0.9663865566253662,\n",
       "   0.9687875509262085,\n",
       "   0.9631853103637695,\n",
       "   0.9689876437187195,\n",
       "   0.9547819495201111],\n",
       "  'prec': [0.9375,\n",
       "   0.9215686321258545,\n",
       "   0.9074074029922485,\n",
       "   0.8474576473236084,\n",
       "   0.9230769276618958,\n",
       "   0.875,\n",
       "   0.9399999976158142,\n",
       "   0.9347826242446899,\n",
       "   0.875,\n",
       "   0.9038461446762085],\n",
       "  'acc': [0.9100000262260437,\n",
       "   0.9200000166893005,\n",
       "   0.9300000071525574,\n",
       "   0.8999999761581421,\n",
       "   0.9300000071525574,\n",
       "   0.9100000262260437,\n",
       "   0.9300000071525574,\n",
       "   0.8899999856948853,\n",
       "   0.9100000262260437,\n",
       "   0.9100000262260437],\n",
       "  'rec': [0.8823529481887817,\n",
       "   0.9215686321258545,\n",
       "   0.9607843160629272,\n",
       "   0.9803921580314636,\n",
       "   0.9411764740943909,\n",
       "   0.9607843160629272,\n",
       "   0.9215686321258545,\n",
       "   0.843137264251709,\n",
       "   0.9607843160629272,\n",
       "   0.9215686321258545],\n",
       "  'f1pos': [0.9090909090909091,\n",
       "   0.9215686274509803,\n",
       "   0.9333333333333333,\n",
       "   0.909090909090909,\n",
       "   0.9320388349514563,\n",
       "   0.9158878504672897,\n",
       "   0.9306930693069307,\n",
       "   0.8865979381443299,\n",
       "   0.9158878504672897,\n",
       "   0.9126213592233009],\n",
       "  'f1neg': [0.9108910891089108,\n",
       "   0.9183673469387755,\n",
       "   0.9263157894736843,\n",
       "   0.888888888888889,\n",
       "   0.9278350515463918,\n",
       "   0.9032258064516128,\n",
       "   0.9292929292929293,\n",
       "   0.8932038834951458,\n",
       "   0.9032258064516128,\n",
       "   0.9072164948453607]}}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eCNN_dict['set_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryings_stuff2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
